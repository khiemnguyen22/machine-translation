{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOUycNIZPMc2P0c7Q3UAQrk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"_3EznmAC4f62"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from keras.preprocessing.text import Tokenizer\n","from keras_preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","import os\n","import string\n","import re\n","import pickle\n","from pickle import dump\n","import unicodedata\n","from unicodedata import normalize\n","import random"]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pWFhZxx-CFyv","executionInfo":{"status":"ok","timestamp":1668471824635,"user_tz":360,"elapsed":2158,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"bde2beb4-f025-4b63-9b38-aef0c276468e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"]}]},{"cell_type":"code","source":["cd gdrive/MyDrive"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EMV9gGpbF5lC","executionInfo":{"status":"ok","timestamp":1668470370656,"user_tz":360,"elapsed":7,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"a3f0acc5-9b29-499c-b7a5-aa681953144f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive\n"]}]},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_JMjfgGJ7f7t","executionInfo":{"status":"ok","timestamp":1666890316951,"user_tz":300,"elapsed":1014,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"3d9b71a8-526a-45a2-d558-d31ef3dafe96"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Oct 27 17:05:16 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    45W / 400W |      0MiB / 40536MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["# Dataset preprocessing"],"metadata":{"id":"DqFN2HRcRRED"}},{"cell_type":"markdown","source":["### Europarl dataset"],"metadata":{"id":"KZK4o7ujRsTV"}},{"cell_type":"code","source":["# load doc into memory\n","def load_doc(filename):\n","\tfile = open(filename, mode='rt', encoding='utf-8')\n","\ttext = file.read()\n","\tfile.close()\n","\treturn text\n"," \n","# split a loaded document into sentences\n","def to_sentences(doc):\n","\treturn doc.strip().split('\\n')\n"," \n","# clean a list of lines\n","def clean_lines(lines):\n","\tcleaned = list()\n","\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n","\ttable = str.maketrans('', '', string.punctuation)\n","\tfor line in lines:\n","\n","\t\tline = normalize('NFD', line).encode('ascii', 'ignore')\n","\t\tline = line.decode('UTF-8')\n","\n","\t\tline = line.split()\n","\n","\t\tline = [word.lower() for word in line]\n","\n","\t\tline = [word.translate(table) for word in line]\n","\n","\t\tline = [re_print.sub('', w) for w in line]\n","\n","\t\tline = [word for word in line if word.isalpha()]\n","\t\tline = ' '.join(line)\n","\t\tline = '<start> ' + line + ' <end>'\n","\t\t# store as string\n","\t\tcleaned.append(line)\n","\treturn cleaned\n"," \n","# save a list of clean sentences to file\n","def save_clean_sentences(sentences, filename):\n","\tdump(sentences, open(filename, 'wb'))\n","\tprint('Saved: %s' % filename)\n","\n","def load_datasets(filename):\n","    return pickle.load(open(filename, 'rb'))\n","\n","def produce_train_test(en, fr, ratio = 0.9, total_size = 5000):\n","    n_train = int(total_size * ratio)\n","    indexes = random.sample(range(total_size), n_train)\n","    trainX =  en[indexes]\n","    trainY = fr[indexes]\n","\n","    testX = en[[i for i in range(total_size) if i not in indexes]]\n","    testY = fr[[i for i in range(total_size) if i not in indexes]]\n","    return trainX, trainY, testX, testY\n","\n","# fit a tokenizer\n","def create_tokenizer(lines):\n","\ttokenizer = Tokenizer(filters = '')\n","\ttokenizer.fit_on_texts(lines)\n","\treturn tokenizer\n","\n","\n","# max sentence length\n","def max_length(lines):\n","\treturn max(len(line.split()) for line in lines)\n","\n","# encode and pad sequences\n","def encode_sequences(tokenizer, length, lines):\n","\tX = tokenizer.texts_to_sequences(lines)\n","\tX = pad_sequences(X, maxlen=length, padding='post')\n","\treturn X\n"," "],"metadata":{"id":"K15x31dSGcdw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load English data\n","filename = 'europarl-v7.fr-en.en'\n","doc = load_doc(filename)\n","en_sentences = to_sentences(doc)\n","en_sentences = clean_lines(en_sentences)\n"," \n","# load French data\n","filename = 'europarl-v7.fr-en.fr'\n","doc = load_doc(filename)\n","fr_sentences = to_sentences(doc)\n","fr_sentences = clean_lines(fr_sentences)"],"metadata":{"id":"N_WSEGKdQ7er"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save cleaned dataset\n","save_clean_sentences(en_sentences, 'english.pkl')\n","save_clean_sentences(fr_sentences, 'french.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aJvVPsgeHLl4","executionInfo":{"status":"ok","timestamp":1668471833303,"user_tz":360,"elapsed":3780,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"78bbfb67-ee93-48c6-b954-c2309b548056"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved: english.pkl\n","Saved: french.pkl\n"]}]},{"cell_type":"code","source":["# load cleaned data to generate datasets\n","en_sentences = load_datasets('english.pkl')\n","fr_sentences = load_datasets('french.pkl')"],"metadata":{"id":"8d2El6q6fQHH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_size = 30000\n","en = np.array(en_sentences[:total_size])\n","fr = np.array(fr_sentences[:total_size])"],"metadata":{"id":"D17dvTQueky1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainX, trainY, testX, testY = produce_train_test(en, fr, total_size = total_size)"],"metadata":{"id":"tYOe1c44YIE0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### manythings dataset"],"metadata":{"id":"hDLFo0eXRf4b"}},{"cell_type":"code","source":["def preprocess_sentence(line):\n","\n","    re_print = re.compile('[^%s]' % re.escape(string.printable))\n","\n","    table = str.maketrans('', '', string.punctuation)\n","\n","    line = normalize('NFD', line).encode('ascii', 'ignore')\n","    line = line.decode('UTF-8')\n","\n","    line = line.split()\n","\n","    line = [word.lower() for word in line]\n","\n","    line = [word.translate(table) for word in line]\n","\n","    line = [re_print.sub('', w) for w in line]\n","\n","    line = [word for word in line if word.isalpha()]\n","    line = ' '.join(line)\n","    line = '<start> ' + line + ' <end>'\n","    return line\n","\n","import io\n","\n","# Create the Dataset\n","def create_dataset(path, num_examples):\n","    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n","\n","    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t', 2)[:-1]]  for l in lines[:num_examples]]\n","    return zip(*word_pairs)\n"],"metadata":{"id":"WF_k3YokqEUH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip 'fra-eng.zip'"],"metadata":{"id":"ruFbwTjwREJv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path_to_file = \"fra.txt\""],"metadata":{"id":"dep5PaXuREVj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["en, fr = create_dataset(path_to_file, None)\n","trainX, trainY, testX, testY = produce_train_test(np.array(en[:50000]), np.array(fr[:50000]), total_size = 50000)"],"metadata":{"id":"JJsXCdA6nynA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Create tokenizer "],"metadata":{"id":"DqRyGLhIRYZj"}},{"cell_type":"code","source":["en_tokenizer = create_tokenizer(en)\n","en_vocab_size = len(en_tokenizer.word_index) + 1\n","en_length = max_length(en)\n","print('English Vocabulary Size: %d' % en_vocab_size)\n","print('English Max Length: %d' % (en_length))\n","\n","fr_tokenizer = create_tokenizer(fr)\n","fr_vocab_size = len(fr_tokenizer.word_index) + 1\n","fr_length = max_length(fr)\n","print('French Vocabulary Size: %d' % fr_vocab_size)\n","print('French Max Length: %d' % (fr_length))\n"," \n","# prepare training data\n","trainX = encode_sequences(en_tokenizer, en_length, trainX)\n","trainY = encode_sequences(fr_tokenizer, fr_length, trainY)\n","\n","# prepare validation data\n","testX = encode_sequences(en_tokenizer, en_length, testX)\n","testY = encode_sequences(en_tokenizer, fr_length, testY)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OwhjH4Wgfzy1","executionInfo":{"status":"ok","timestamp":1668472775653,"user_tz":360,"elapsed":3171,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"d4da614e-9fe9-4318-c7f7-350fbb13b771"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["English Vocabulary Size: 17558\n","English Max Length: 149\n","French Vocabulary Size: 25873\n","French Max Length: 154\n"]}]},{"cell_type":"code","source":["trainX.shape, trainY.shape, testX.shape, testY.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wBL6O2cmgtPd","executionInfo":{"status":"ok","timestamp":1668472776515,"user_tz":360,"elapsed":1,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"6e928f8c-7f17-451a-9cbd-19581acea37e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((27000, 149), (27000, 154), (3000, 149), (3000, 154))"]},"metadata":{},"execution_count":107}]},{"cell_type":"code","source":["def convert(lang, tensor):\n","  for t in tensor:\n","    if t != 0:\n","      print (\"%d ----> %s\" % (t, lang.index_word[t]))\n","      \n","print (\"Input Language; index to word mapping\")\n","convert(en_tokenizer, trainX[0])\n","print ()\n","print (\"Target Language; index to word mapping\")\n","convert(fr_tokenizer, trainY[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3CL1zkgsavIP","executionInfo":{"status":"ok","timestamp":1668472778583,"user_tz":360,"elapsed":5,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"9bcd14f7-7752-4f85-b6e4-746337e3a6a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input Language; index to word mapping\n","2 ----> <start>\n","46 ----> these\n","19 ----> are\n","161 ----> areas\n","124 ----> where\n","1 ----> the\n","1344 ----> citizen\n","47 ----> can\n","170 ----> see\n","6 ----> and\n","500 ----> understand\n","1 ----> the\n","686 ----> benefit\n","4 ----> of\n","67 ----> europe\n","3 ----> <end>\n","\n","Target Language; index to word mapping\n","2 ----> <start>\n","23 ----> il\n","106 ----> s\n","457 ----> agit\n","9 ----> des\n","392 ----> domaines\n","36 ----> ou\n","7 ----> le\n","1033 ----> citoyen\n","6858 ----> distingue\n","1 ----> de\n","111 ----> maniere\n","14869 ----> perceptible\n","25 ----> l\n","3327 ----> utilite\n","1 ----> de\n","165 ----> leurope\n","3 ----> <end>\n"]}]},{"cell_type":"markdown","source":["# Model Parameters"],"metadata":{"id":"ZM4rjYGnavkU"}},{"cell_type":"code","source":["BUFFER_SIZE = len(trainX)\n","BATCH_SIZE = 64\n","steps_per_epoch = len(trainY)//BATCH_SIZE\n","embedding_dim = 256\n","units = 256\n","architecture = 'gru' # gru, simple RNN"],"metadata":{"id":"5iVIC442LJ3o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = tf.data.Dataset.from_tensor_slices((trainX, trainY)).shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"],"metadata":{"id":"tp5Iw_n0KNLm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["example_input_batch, example_target_batch = next(iter(dataset))\n","example_input_batch.shape, example_target_batch.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fcPqSjSfLa9S","executionInfo":{"status":"ok","timestamp":1668472783099,"user_tz":360,"elapsed":785,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"cf6433fa-e5b1-42af-b88c-275767024f2c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([64, 149]), TensorShape([64, 154]))"]},"metadata":{},"execution_count":111}]},{"cell_type":"markdown","source":["# Simple NMT model"],"metadata":{"id":"RvcFd9kXHbu5"}},{"cell_type":"code","source":["from keras.utils.vis_utils import plot_model\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense, Embedding, RepeatVector, TimeDistributed, SimpleRNN\n","from keras.callbacks import ModelCheckpoint"],"metadata":{"id":"6OvycN1uibDv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n","\tmodel = Sequential()\n","\tmodel.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n","\tmodel.add(SimpleRNN(n_units))\n","\tmodel.add(RepeatVector(tar_timesteps))\n","\tmodel.add(SimpleRNN(n_units, return_sequences=True))\n","\tmodel.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n","\treturn model"],"metadata":{"id":"qN2_zcv4hsd4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = define_model(en_vocab_size, fr_vocab_size, en_length, fr_length, 256)\n","model.compile(optimizer='adam', loss='categorical_crossentropy')\n","print(model.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FMtPK7OgiTPc","executionInfo":{"status":"ok","timestamp":1666901346381,"user_tz":300,"elapsed":286,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"8bf7ad06-0545-4332-d95d-2a96342b0faa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_2 (Embedding)     (None, 54, 256)           3908864   \n","                                                                 \n"," simple_rnn_2 (SimpleRNN)    (None, 256)               131328    \n","                                                                 \n"," repeat_vector (RepeatVector  (None, 65, 256)          0         \n"," )                                                               \n","                                                                 \n"," simple_rnn_3 (SimpleRNN)    (None, 65, 256)           131328    \n","                                                                 \n"," time_distributed (TimeDistr  (None, 65, 24468)        6288276   \n"," ibuted)                                                         \n","                                                                 \n","=================================================================\n","Total params: 10,459,796\n","Trainable params: 10,459,796\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["# checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n","model.fit(trainX, trainY1, epochs=30, batch_size=64, validation_data=(testX, testY1))"],"metadata":{"id":"mxu_1lAsich0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666901873013,"user_tz":300,"elapsed":517404,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"df489774-85d5-4cc3-9c13-ad2184f52045"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","71/71 [==============================] - 22s 269ms/step - loss: 2.2350 - val_loss: 0.3688\n","Epoch 2/30\n","71/71 [==============================] - 16s 232ms/step - loss: 0.5519 - val_loss: 0.2693\n","Epoch 3/30\n","71/71 [==============================] - 16s 230ms/step - loss: 0.4066 - val_loss: 0.2776\n","Epoch 4/30\n","71/71 [==============================] - 16s 229ms/step - loss: 0.3748 - val_loss: 0.3067\n","Epoch 5/30\n","71/71 [==============================] - 17s 234ms/step - loss: 0.3568 - val_loss: 0.3221\n","Epoch 6/30\n","71/71 [==============================] - 17s 234ms/step - loss: 0.3437 - val_loss: 0.3465\n","Epoch 7/30\n","71/71 [==============================] - 17s 235ms/step - loss: 0.3341 - val_loss: 0.3609\n","Epoch 8/30\n","71/71 [==============================] - 16s 229ms/step - loss: 0.3247 - val_loss: 0.3615\n","Epoch 9/30\n","71/71 [==============================] - 16s 232ms/step - loss: 0.3182 - val_loss: 0.3939\n","Epoch 10/30\n","71/71 [==============================] - 16s 233ms/step - loss: 0.3122 - val_loss: 0.3904\n","Epoch 11/30\n","71/71 [==============================] - 17s 233ms/step - loss: 0.3069 - val_loss: 0.4087\n","Epoch 12/30\n","71/71 [==============================] - 17s 235ms/step - loss: 0.3016 - val_loss: 0.4211\n","Epoch 13/30\n","71/71 [==============================] - 16s 230ms/step - loss: 0.2951 - val_loss: 0.4286\n","Epoch 14/30\n","71/71 [==============================] - 16s 232ms/step - loss: 0.2895 - val_loss: 0.4227\n","Epoch 15/30\n","71/71 [==============================] - 16s 232ms/step - loss: 0.2818 - val_loss: 0.4214\n","Epoch 16/30\n","71/71 [==============================] - 16s 231ms/step - loss: 0.2757 - val_loss: 0.4418\n","Epoch 17/30\n","71/71 [==============================] - 16s 231ms/step - loss: 0.2699 - val_loss: 0.4473\n","Epoch 18/30\n","71/71 [==============================] - 16s 230ms/step - loss: 0.2655 - val_loss: 0.4774\n","Epoch 19/30\n","71/71 [==============================] - 16s 230ms/step - loss: 0.2599 - val_loss: 0.4777\n","Epoch 20/30\n","71/71 [==============================] - 16s 231ms/step - loss: 0.2549 - val_loss: 0.4810\n","Epoch 21/30\n","71/71 [==============================] - 16s 230ms/step - loss: 0.2499 - val_loss: 0.4853\n","Epoch 22/30\n","71/71 [==============================] - 16s 230ms/step - loss: 0.2451 - val_loss: 0.4912\n","Epoch 23/30\n","71/71 [==============================] - 16s 231ms/step - loss: 0.2399 - val_loss: 0.4905\n","Epoch 24/30\n","71/71 [==============================] - 16s 231ms/step - loss: 0.2338 - val_loss: 0.4854\n","Epoch 25/30\n","71/71 [==============================] - 16s 231ms/step - loss: 0.2297 - val_loss: 0.4913\n","Epoch 26/30\n","71/71 [==============================] - 17s 234ms/step - loss: 0.2237 - val_loss: 0.5048\n","Epoch 27/30\n","71/71 [==============================] - 17s 232ms/step - loss: 0.2193 - val_loss: 0.4998\n","Epoch 28/30\n","71/71 [==============================] - 16s 231ms/step - loss: 0.2137 - val_loss: 0.5260\n","Epoch 29/30\n","71/71 [==============================] - 16s 228ms/step - loss: 0.2077 - val_loss: 0.5217\n","Epoch 30/30\n","71/71 [==============================] - 16s 232ms/step - loss: 0.2036 - val_loss: 0.5359\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fef34ff6590>"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["model.save('translate_en_fr.h5')"],"metadata":{"id":"L_5ndaPUHY7d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def word_for_id(integer, tokenizer):\n","\tfor word, index in tokenizer.word_index.items():\n","\t\tif index == integer:\n","\t\t\treturn word\n","\treturn None\n"," \n","# generate target given source sequence\n","def predict_sequence(model, tokenizer, source):\n","    source = source.reshape((1, source.shape[0]))\n","    prediction = model.predict(source, verbose=0)[0]\n","    integers = [np.argmax(vector) for vector in prediction]\n","    target = list()\n","    input = ''\n","    for i in integers:\n","        word = word_for_id(i, tokenizer)\n","        if word is None:\n","            break\n","        target.append(word)\n","    return ' '.join(target)"],"metadata":{"id":"uL-aIYW7iwhi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["source = trainX[0]\n","predict_sequence(model, fr_tokenizer, source)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"hbqgEJtsiyJw","executionInfo":{"status":"ok","timestamp":1666902091834,"user_tz":300,"elapsed":79,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"d8fe3605-3f6e-4e3b-93d4-1ca0e4f992a3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<start> tu etes sympa . <end>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":53}]},{"cell_type":"markdown","source":["# Encoder class"],"metadata":{"id":"GiZRSIoiHfTZ"}},{"cell_type":"code","source":["# Encoder class\n","class Encoder(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n","        super(Encoder, self).__init__()\n","        self.batch_sz = batch_sz\n","        self.enc_units = enc_units\n","\n","        # Embed the vocab to a dense embedding \n","        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","\n","        # GRU Layer\n","        # glorot_uniform: Initializer for the recurrent_kernel weights matrix, \n","        # used for the linear transformation of the recurrent state\n","        if architecture == 'gru':\n","            self.rnn = tf.keras.layers.GRU(self.enc_units,\n","                                            return_sequences=True,\n","                                            return_state=True,\n","                                            recurrent_initializer='glorot_uniform')\n","        if architecture == 'rnn':\n","            self.rnn = tf.keras.layers.SimpleRNN(self.enc_units,\n","                                            return_sequences=True,\n","                                            return_state=True,\n","                                            recurrent_initializer='glorot_uniform')     \n","        self.rnn = tf.keras.layers.Bidirectional(self.rnn)\n","\n","    # Encoder network comprises an Embedding layer followed by a GRU layer\n","    def call(self, x, hidden):\n","        x = self.embedding(x)\n","        output, forward_state, backward_state = self.rnn(x, initial_state=hidden)\n","        return output, tf.keras.layers.Concatenate()([forward_state, backward_state])\n","\n","    # To initialize the hidden state\n","    def initialize_hidden_state(self):\n","        return [tf.zeros((self.batch_sz, self.enc_units)) for i in range(2)]"],"metadata":{"id":"ol5o64Ou_Wf_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder = Encoder(en_vocab_size, embedding_dim, units, BATCH_SIZE)\n","\n","sample_hidden = encoder.initialize_hidden_state()\n","sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n","\n","print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n","print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZamiUpQ-LgJ_","executionInfo":{"status":"ok","timestamp":1668472786382,"user_tz":360,"elapsed":9,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"6e172284-18b3-4681-a0f3-70f9328919b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoder output shape: (batch size, sequence length, units) (64, 149, 512)\n","Encoder Hidden state shape: (batch size, units) (64, 512)\n"]}]},{"cell_type":"markdown","source":["# Attention layer"],"metadata":{"id":"aTUJxoQZH3A4"}},{"cell_type":"code","source":["# Attention Mechanism\n","class Attention(tf.keras.layers.Layer):\n","  def __init__(self, units):\n","    super(Attention, self).__init__()\n","    self.W1 = tf.keras.layers.Dense(units)\n","    self.W2 = tf.keras.layers.Dense(units)\n","    self.V = tf.keras.layers.Dense(1)\n","\n","  def call(self, query, values):\n","    # query hidden state shape == (batch_size, hidden size)\n","    # values shape == (batch_size, max_len, hidden size)\n","\n","    # we are doing this to broadcast addition along the time axis to calculate the score\n","    # query_with_time_axis shape == (batch_size, 1, hidden size)\n","    query_with_time_axis = tf.expand_dims(query, 1)\n","\n","    # score shape == (batch_size, max_length, 1)\n","    # we get 1 at the last axis because we are applying score to self.V\n","    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n","    score = self.V(tf.nn.tanh(\n","        self.W1(query_with_time_axis) + self.W2(values)))\n","\n","    # attention_weights shape == (batch_size, max_length, 1)\n","    attention_weights = tf.nn.softmax(score, axis=1)\n","\n","    # context_vector shape after sum == (batch_size, hidden_size)\n","    context_vector = attention_weights * values\n","    context_vector = tf.reduce_sum(context_vector, axis=1)\n","\n","    return context_vector, attention_weights"],"metadata":{"id":"e5wKEbDeH2hB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["attention_layer = Attention(10)\n","attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n","\n","print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n","print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"],"metadata":{"id":"7_YOjEzZL2LN","executionInfo":{"status":"ok","timestamp":1668472786383,"user_tz":360,"elapsed":6,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e260a23e-3036-42ba-d39e-f6b363405bde"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Attention result shape: (batch size, units) (64, 512)\n","Attention weights shape: (batch_size, sequence_length, 1) (64, 149, 1)\n"]}]},{"cell_type":"markdown","source":["# Decoder Class"],"metadata":{"id":"mfTebVydH8eO"}},{"cell_type":"code","source":["# Decoder class\n","class Decoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n","    super(Decoder, self).__init__()\n","    self.batch_sz = batch_sz\n","    self.dec_units = dec_units\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.SimpleRNN(self.dec_units,\n","                                   return_sequences=True,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","    self.fc = tf.keras.layers.Dense(vocab_size)\n","\n","    # Used for attention\n","    self.attention = Attention(self.dec_units)\n","\n","  def call(self, x, hidden, enc_output):\n","    # x shape == (batch_size, 1)\n","    # hidden shape == (batch_size, max_length)\n","    # enc_output shape == (batch_size, max_length, hidden_size)\n","\n","    # context_vector shape == (batch_size, hidden_size)\n","    # attention_weights shape == (batch_size, max_length, 1)\n","    context_vector, attention_weights = self.attention(hidden, enc_output)\n","\n","    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n","    x = self.embedding(x)\n","\n","    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n","    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n","\n","    # passing the concatenated vector to the GRU\n","    output, state = self.gru(x)\n","\n","    # output shape == (batch_size * 1, hidden_size)\n","    output = tf.reshape(output, (-1, output.shape[2]))\n","\n","    # output shape == (batch_size, vocab)\n","    x = self.fc(output)\n","\n","    return x, state, attention_weights"],"metadata":{"id":"0Y3BMguw_-JD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["decoder = Decoder(fr_vocab_size, embedding_dim, units * 2, BATCH_SIZE)\n","\n","sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n","                                      sample_hidden, sample_output)\n","\n","print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"],"metadata":{"id":"IqzCT8xVL_3k","executionInfo":{"status":"ok","timestamp":1668472788183,"user_tz":360,"elapsed":2,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"922691b8-2c59-4310-9003-6a0ab96ed2bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Decoder output shape: (batch_size, vocab size) (64, 25873)\n"]}]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"gwyUNfIQP20t"}},{"cell_type":"code","source":["# Initialize optimizer and loss functions\n","optimizer = tf.keras.optimizers.Adam()\n","\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')\n","\n","# Loss function\n","def loss_function(real, pred):\n","\n","  # Take care of the padding. Not all sequences are of equal length.\n","  # If there's a '0' in the sequence, the loss is being nullified\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  loss_ = loss_object(real, pred)\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype)\n","  loss_ *= mask\n","\n","  return tf.reduce_mean(loss_)"],"metadata":{"id":"mkibV-bzMAMS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","checkpoint_dir = './europarl_training_checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n","                                 encoder=encoder,\n","                                 decoder=decoder)"],"metadata":{"id":"mL-Y6lXWP4yD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@tf.function\n","def train_step(inp, targ, enc_hidden):\n","  loss = 0\n","\n","  # tf.GradientTape() -- record operations for automatic differentiation\n","  with tf.GradientTape() as tape:\n","    enc_output, enc_hidden = encoder(inp, enc_hidden)\n","\n","    # dec_hidden is used by attention, hence is the same enc_hidden\n","    dec_hidden = enc_hidden\n","\n","    # <start> token is the initial decoder input\n","    dec_input = tf.expand_dims([fr_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n","\n","    # Teacher forcing - feeding the target as the next input\n","    for t in range(1, targ.shape[1]):\n","\n","      # Pass enc_output to the decoder\n","      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n","\n","      # Compute the loss\n","      loss += loss_function(targ[:, t], predictions)\n","\n","      # Use teacher forcing\n","      dec_input = tf.expand_dims(targ[:, t], 1)\n","\n","  # As this function is called per batch, compute the batch_loss\n","  batch_loss = (loss / int(targ.shape[1]))\n","\n","  # Get the model's variables\n","  variables = encoder.trainable_variables + decoder.trainable_variables\n","\n","  # Compute the gradients\n","  gradients = tape.gradient(loss, variables)\n","\n","  # Update the variables of the model/network\n","  optimizer.apply_gradients(zip(gradients, variables))\n","\n","  return batch_loss"],"metadata":{"id":"MNiTqwl6P7mt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","EPOCHS = 30\n","history = []\n","# Training loop\n","for epoch in range(EPOCHS):\n","  start = time.time()\n","\n","  # Initialize the hidden state\n","  enc_hidden = encoder.initialize_hidden_state()\n","  total_loss = 0\n","\n","  # Loop through the dataset\n","  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n","\n","    # Call the train method\n","    batch_loss = train_step(inp, targ, enc_hidden)\n","\n","    # Compute the loss (per batch)\n","    total_loss += batch_loss\n","\n","    if batch % 100 == 0:\n","      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n","                                                   batch,\n","                                                   batch_loss.numpy()))\n","  # Save (checkpoint) the model every 2 epochs\n","  if (epoch + 1) % 2 == 0:\n","    checkpoint.save(file_prefix = checkpoint_prefix)\n","\n","  # Output the loss observed until that epoch\n","  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n","                                      total_loss / steps_per_epoch))\n","  \n","  history.append(total_loss / steps_per_epoch)\n","  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"],"metadata":{"id":"RM3qVshkQAbR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668494031958,"user_tz":360,"elapsed":21237555,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"b1c66ad6-cd64-41b1-cd28-7ef06066490e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 Batch 0 Loss 1.8587\n","Epoch 1 Batch 100 Loss 1.1893\n","Epoch 1 Batch 200 Loss 1.2692\n","Epoch 1 Batch 300 Loss 1.2345\n","Epoch 1 Batch 400 Loss 1.2772\n","Epoch 1 Loss 1.2637\n","Time taken for 1 epoch 840.9262318611145 sec\n","\n","Epoch 2 Batch 0 Loss 1.2112\n","Epoch 2 Batch 100 Loss 1.0780\n","Epoch 2 Batch 200 Loss 1.1535\n","Epoch 2 Batch 300 Loss 1.2694\n","Epoch 2 Batch 400 Loss 1.1514\n","Epoch 2 Loss 1.2439\n","Time taken for 1 epoch 705.4816184043884 sec\n","\n","Epoch 3 Batch 0 Loss 1.2305\n","Epoch 3 Batch 100 Loss 1.2883\n","Epoch 3 Batch 200 Loss 1.1522\n","Epoch 3 Batch 300 Loss 1.0928\n","Epoch 3 Batch 400 Loss 1.1496\n","Epoch 3 Loss 1.2438\n","Time taken for 1 epoch 703.3634221553802 sec\n","\n","Epoch 4 Batch 0 Loss 1.0854\n","Epoch 4 Batch 100 Loss 1.2947\n","Epoch 4 Batch 200 Loss 1.1255\n","Epoch 4 Batch 300 Loss 1.1887\n","Epoch 4 Batch 400 Loss 1.1770\n","Epoch 4 Loss 1.2438\n","Time taken for 1 epoch 703.8978760242462 sec\n","\n","Epoch 5 Batch 0 Loss 1.1210\n","Epoch 5 Batch 100 Loss 1.1275\n","Epoch 5 Batch 200 Loss 1.4155\n","Epoch 5 Batch 300 Loss 1.1118\n","Epoch 5 Batch 400 Loss 1.2043\n","Epoch 5 Loss 1.2374\n","Time taken for 1 epoch 703.7443051338196 sec\n","\n","Epoch 6 Batch 0 Loss 1.1908\n","Epoch 6 Batch 100 Loss 0.9422\n","Epoch 6 Batch 200 Loss 0.9824\n","Epoch 6 Batch 300 Loss 1.1185\n","Epoch 6 Batch 400 Loss 0.9426\n","Epoch 6 Loss 1.0368\n","Time taken for 1 epoch 708.5696301460266 sec\n","\n","Epoch 7 Batch 0 Loss 0.8834\n","Epoch 7 Batch 100 Loss 0.9559\n","Epoch 7 Batch 200 Loss 1.0216\n","Epoch 7 Batch 300 Loss 0.9552\n","Epoch 7 Batch 400 Loss 0.8141\n","Epoch 7 Loss 0.9237\n","Time taken for 1 epoch 708.6034462451935 sec\n","\n","Epoch 8 Batch 0 Loss 0.7874\n","Epoch 8 Batch 100 Loss 0.9101\n","Epoch 8 Batch 200 Loss 0.8384\n","Epoch 8 Batch 300 Loss 0.7787\n","Epoch 8 Batch 400 Loss 0.8251\n","Epoch 8 Loss 0.8479\n","Time taken for 1 epoch 709.8675861358643 sec\n","\n","Epoch 9 Batch 0 Loss 0.7221\n","Epoch 9 Batch 100 Loss 0.7165\n","Epoch 9 Batch 200 Loss 0.6549\n","Epoch 9 Batch 300 Loss 0.8149\n","Epoch 9 Batch 400 Loss 0.7887\n","Epoch 9 Loss 0.7786\n","Time taken for 1 epoch 708.6611335277557 sec\n","\n","Epoch 10 Batch 0 Loss 0.6245\n","Epoch 10 Batch 100 Loss 0.5572\n","Epoch 10 Batch 200 Loss 0.7887\n","Epoch 10 Batch 300 Loss 0.7061\n","Epoch 10 Batch 400 Loss 0.6526\n","Epoch 10 Loss 0.7139\n","Time taken for 1 epoch 709.1633207798004 sec\n","\n","Epoch 11 Batch 0 Loss 0.6147\n","Epoch 11 Batch 100 Loss 0.6252\n","Epoch 11 Batch 200 Loss 0.7358\n","Epoch 11 Batch 300 Loss 0.6489\n","Epoch 11 Batch 400 Loss 0.6536\n","Epoch 11 Loss 0.6713\n","Time taken for 1 epoch 708.4000909328461 sec\n","\n","Epoch 12 Batch 0 Loss 0.6219\n","Epoch 12 Batch 100 Loss 0.5738\n","Epoch 12 Batch 200 Loss 0.6180\n","Epoch 12 Batch 300 Loss 0.6766\n","Epoch 12 Batch 400 Loss 0.5951\n","Epoch 12 Loss 0.6151\n","Time taken for 1 epoch 709.5891482830048 sec\n","\n","Epoch 13 Batch 0 Loss 0.6151\n","Epoch 13 Batch 100 Loss 0.4601\n","Epoch 13 Batch 200 Loss 0.5570\n","Epoch 13 Batch 300 Loss 0.6175\n","Epoch 13 Batch 400 Loss 0.6039\n","Epoch 13 Loss 0.5671\n","Time taken for 1 epoch 702.356584072113 sec\n","\n","Epoch 14 Batch 0 Loss 0.4550\n","Epoch 14 Batch 100 Loss 0.5934\n","Epoch 14 Batch 200 Loss 0.5156\n","Epoch 14 Batch 300 Loss 0.5040\n","Epoch 14 Batch 400 Loss 0.6187\n","Epoch 14 Loss 0.5451\n","Time taken for 1 epoch 700.241866350174 sec\n","\n","Epoch 15 Batch 0 Loss 0.4737\n","Epoch 15 Batch 100 Loss 0.4745\n","Epoch 15 Batch 200 Loss 0.4316\n","Epoch 15 Batch 300 Loss 0.6090\n","Epoch 15 Batch 400 Loss 0.5134\n","Epoch 15 Loss 0.4966\n","Time taken for 1 epoch 706.4656398296356 sec\n","\n","Epoch 16 Batch 0 Loss 0.4042\n","Epoch 16 Batch 100 Loss 0.5163\n","Epoch 16 Batch 200 Loss 0.4464\n","Epoch 16 Batch 300 Loss 0.4556\n","Epoch 16 Batch 400 Loss 0.4087\n","Epoch 16 Loss 0.4610\n","Time taken for 1 epoch 700.6234576702118 sec\n","\n","Epoch 17 Batch 0 Loss 0.4091\n","Epoch 17 Batch 100 Loss 0.4030\n","Epoch 17 Batch 200 Loss 0.4454\n","Epoch 17 Batch 300 Loss 0.4598\n","Epoch 17 Batch 400 Loss 0.3137\n","Epoch 17 Loss 0.4290\n","Time taken for 1 epoch 699.1925363540649 sec\n","\n","Epoch 18 Batch 0 Loss 0.3809\n","Epoch 18 Batch 100 Loss 0.3951\n","Epoch 18 Batch 200 Loss 0.4200\n","Epoch 18 Batch 300 Loss 0.4852\n","Epoch 18 Batch 400 Loss 0.5021\n","Epoch 18 Loss 0.4614\n","Time taken for 1 epoch 700.1754379272461 sec\n","\n","Epoch 19 Batch 0 Loss 0.4542\n","Epoch 19 Batch 100 Loss 0.3524\n","Epoch 19 Batch 200 Loss 0.4488\n","Epoch 19 Batch 300 Loss 0.3967\n","Epoch 19 Batch 400 Loss 0.3948\n","Epoch 19 Loss 0.4129\n","Time taken for 1 epoch 700.5126101970673 sec\n","\n","Epoch 20 Batch 0 Loss 0.3354\n","Epoch 20 Batch 100 Loss 0.3362\n","Epoch 20 Batch 200 Loss 0.3235\n","Epoch 20 Batch 300 Loss 0.4016\n","Epoch 20 Batch 400 Loss 0.4286\n","Epoch 20 Loss 0.3735\n","Time taken for 1 epoch 701.4116082191467 sec\n","\n","Epoch 21 Batch 0 Loss 0.3078\n","Epoch 21 Batch 100 Loss 0.3794\n","Epoch 21 Batch 200 Loss 0.3256\n","Epoch 21 Batch 300 Loss 0.3155\n","Epoch 21 Batch 400 Loss 0.3238\n","Epoch 21 Loss 0.3525\n","Time taken for 1 epoch 699.9179935455322 sec\n","\n","Epoch 22 Batch 0 Loss 0.2967\n","Epoch 22 Batch 100 Loss 0.2896\n","Epoch 22 Batch 200 Loss 0.3527\n","Epoch 22 Batch 300 Loss 0.3067\n","Epoch 22 Batch 400 Loss 0.3035\n","Epoch 22 Loss 0.3305\n","Time taken for 1 epoch 700.1915326118469 sec\n","\n","Epoch 23 Batch 0 Loss 0.2664\n","Epoch 23 Batch 100 Loss 0.3139\n","Epoch 23 Batch 200 Loss 0.2759\n","Epoch 23 Batch 300 Loss 0.3562\n","Epoch 23 Batch 400 Loss 0.2891\n","Epoch 23 Loss 0.3186\n","Time taken for 1 epoch 699.6749219894409 sec\n","\n","Epoch 24 Batch 0 Loss 0.3076\n","Epoch 24 Batch 100 Loss 0.3242\n","Epoch 24 Batch 200 Loss 0.3183\n","Epoch 24 Batch 300 Loss 0.2868\n","Epoch 24 Batch 400 Loss 0.3655\n","Epoch 24 Loss 0.3080\n","Time taken for 1 epoch 700.0897240638733 sec\n","\n","Epoch 25 Batch 0 Loss 0.3181\n","Epoch 25 Batch 100 Loss 0.3555\n","Epoch 25 Batch 200 Loss 0.2976\n","Epoch 25 Batch 300 Loss 0.3127\n","Epoch 25 Batch 400 Loss 0.3154\n","Epoch 25 Loss 0.3021\n","Time taken for 1 epoch 699.3732218742371 sec\n","\n","Epoch 26 Batch 0 Loss 0.2691\n","Epoch 26 Batch 100 Loss 0.2655\n","Epoch 26 Batch 200 Loss 0.2775\n","Epoch 26 Batch 300 Loss 0.3048\n","Epoch 26 Batch 400 Loss 0.3279\n","Epoch 26 Loss 0.2836\n","Time taken for 1 epoch 701.3990435600281 sec\n","\n","Epoch 27 Batch 0 Loss 0.3174\n","Epoch 27 Batch 100 Loss 0.2532\n","Epoch 27 Batch 200 Loss 0.2655\n","Epoch 27 Batch 300 Loss 0.2759\n","Epoch 27 Batch 400 Loss 0.2195\n","Epoch 27 Loss 0.2697\n","Time taken for 1 epoch 699.8261408805847 sec\n","\n","Epoch 28 Batch 0 Loss 0.2758\n","Epoch 28 Batch 100 Loss 0.2396\n","Epoch 28 Batch 200 Loss 0.2156\n","Epoch 28 Batch 300 Loss 0.2811\n","Epoch 28 Batch 400 Loss 0.2586\n","Epoch 28 Loss 0.2452\n","Time taken for 1 epoch 700.4255485534668 sec\n","\n","Epoch 29 Batch 0 Loss 0.1783\n","Epoch 29 Batch 100 Loss 0.2171\n","Epoch 29 Batch 200 Loss 0.2377\n","Epoch 29 Batch 300 Loss 0.2571\n","Epoch 29 Batch 400 Loss 0.3027\n","Epoch 29 Loss 0.2568\n","Time taken for 1 epoch 700.1441397666931 sec\n","\n","Epoch 30 Batch 0 Loss 0.2160\n","Epoch 30 Batch 100 Loss 0.2665\n","Epoch 30 Batch 200 Loss 0.2259\n","Epoch 30 Batch 300 Loss 0.2591\n","Epoch 30 Batch 400 Loss 0.2445\n","Epoch 30 Loss 0.2517\n","Time taken for 1 epoch 703.8710837364197 sec\n","\n"]}]},{"cell_type":"markdown","source":["# Evaluation"],"metadata":{"id":"AsyjZbrIbyXh"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","\n","def plot_training(history):\n","    loss = history\n","    epochs = range(1, len(history) + 1)\n","    \n","    # Plot training and validation loss\n","    plt.plot(epochs, loss, 'bo', label = 'training loss')\n","    plt.title('training loss')\n","    plt.legend()\n"],"metadata":{"id":"afXEh0I3_Ygq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_training(history)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"id":"_y7QDlvX_Zi7","executionInfo":{"status":"ok","timestamp":1668494171458,"user_tz":360,"elapsed":3,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"d26913e5-4445-4717-d58f-f944451fef57"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["import numpy as np\n","\n","# Evaluate function -- similar to the training loop\n","def evaluate(sentence, max_length_inp, max_length_targ, inp_lang, targ_lang):\n","\n","  # Attention plot (to be plotted later on) -- initialized with max_lengths of both target and input\n","  attention_plot = np.zeros((max_length_targ, max_length_inp))\n","\n","  # Preprocess the sentence given\n","  sentence = preprocess_sentence(sentence)\n","\n","  # Fetch the indices concerning the words in the sentence and pad the sequence\n","  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n","  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n","                                                         maxlen=max_length_inp,\n","                                                         padding='post')\n","  # Convert the inputs to tensors\n","  inputs = tf.convert_to_tensor(inputs)\n","\n","  result = ''\n","\n","  hidden = [tf.zeros((1, units)) for i in range(2)]\n","  enc_out, enc_hidden = encoder(inputs, hidden)\n","\n","  dec_hidden = enc_hidden\n","  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n","\n","  # Loop until the max_length is reached for the target lang (ENGLISH)\n","  for t in range(max_length_targ):\n","    predictions, dec_hidden, attention_weights = decoder(dec_input,\n","                                                         dec_hidden,\n","                                                         enc_out)\n","\n","    # Store the attention weights to plot later on\n","    attention_weights = tf.reshape(attention_weights, (-1, ))\n","    attention_plot[t] = attention_weights.numpy()\n","\n","    # Get the prediction with the maximum attention\n","    predicted_id = tf.argmax(predictions[0]).numpy()\n","\n","    # Append the token to the result\n","    result += targ_lang.index_word[predicted_id] + ' '\n","\n","    # If <end> token is reached, return the result, input, and attention plot\n","    if targ_lang.index_word[predicted_id] == '<end>':\n","      return result, sentence, attention_plot\n","\n","    # The predicted ID is fed back into the model\n","    dec_input = tf.expand_dims([predicted_id], 0)\n","\n","  return result, sentence, attention_plot"],"metadata":{"id":"87W9T43zaHYE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","# Function for plotting the attention weights\n","def plot_attention(attention, sentence, predicted_sentence):\n","  fig = plt.figure(figsize=(10,10))\n","  ax = fig.add_subplot(1, 1, 1)\n","  ax.matshow(attention, cmap='viridis')\n","\n","  fontdict = {'fontsize': 14}\n","\n","  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n","  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n","\n","  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","  plt.show()"],"metadata":{"id":"aRVdeXwvRnlO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Translate function (which internally calls the evaluate function)\n","def translate(sentence, max_length_inp, max_length_targ, inp_lang, targ_lang):\n","  result, sentence, attention_plot = evaluate(sentence, max_length_inp, max_length_targ, inp_lang, targ_lang)\n","\n","  print('Input: %s' % (sentence))\n","  print('Predicted translation: {}'.format(result))\n","\n","  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n","  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"],"metadata":{"id":"-bY2tITlRwzW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uDYOIqx3Gl7u","executionInfo":{"status":"ok","timestamp":1668494181460,"user_tz":360,"elapsed":933,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"2a405a22-ce5a-45b1-eeb9-884d81c43997"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7eff86e3f790>"]},"metadata":{},"execution_count":130}]},{"cell_type":"code","source":["sentence = 'my name is'\n","translate(sentence, trainX.shape[1], trainY.shape[1], en_tokenizer, fr_tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":579},"id":"Ri-EDwReE5N2","executionInfo":{"status":"ok","timestamp":1668494207768,"user_tz":360,"elapsed":5,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"61dec842-9050-4358-edaa-021f8f6f734c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: <start> my name is <end>\n","Predicted translation: je revendique <end> \n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x720 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["### Bleu score"],"metadata":{"id":"XtzobayqbxP3"}},{"cell_type":"code","source":["from nltk.translate.bleu_score import corpus_bleu\n","\n","def code_to_text(sentence, tokenizer):\n","    result = ''\n","    for j in sentence:\n","        if j != 2 and j != 1:\n","            result += tokenizer.index_word[j] + ' '\n","        if j == 2:\n","            break\n","    return result\n","\n","def evaluate_model(testX, testY, max_length_inp, max_length_targ, inp_lang, targ_lang):\n","    actual, predicted = [], []\n","    bleu = 0\n","    for i, sentence in enumerate(testX):\n","        \n","        # convert encoded source back to text\n","        og_sentence = code_to_text(sentence, inp_lang)\n","        translation = code_to_text(testY[i], targ_lang)\n","        # translate to target lang\n","        result, sentence, attention_plot = evaluate(og_sentence, max_length_inp, max_length_targ, inp_lang, targ_lang)\n","        if i < 20:\n","            print('src=[%s], target=[%s], predicted=[%s]\\n' % (og_sentence, translation, result))\n","        actual.append([sentence.split()])\n","        predicted.append(result.split()[:-1])\n","\n","    print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n","    print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.0, 1, 0, 0)))\n","    print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0, 0, 1, 0)))\n","    print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0, 0, 0, 1)))"],"metadata":{"id":"Psf2JBfPHwko"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluate_model(trainX, trainY, trainX.shape[1], trainY.shape[1], en_tokenizer, fr_tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":311},"id":"drxJ1EkJiiUT","executionInfo":{"status":"error","timestamp":1668494220196,"user_tz":360,"elapsed":9,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"16bc1945-f682-453b-8353-6204b7449903"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-135-9ffeb18ddc49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfr_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-134-31ec9d362b85>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(testX, testY, max_length_inp, max_length_targ, inp_lang, targ_lang)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtranslation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode_to_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg_lang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# translate to target lang\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mog_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length_targ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg_lang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'src=[%s], target=[%s], predicted=[%s]\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mog_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-127-740ba33bfa0e>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(sentence, max_length_inp, max_length_targ, inp_lang, targ_lang)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m# Fetch the indices concerning the words in the sentence and pad the sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minp_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n\u001b[1;32m     15\u001b[0m                                                          \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length_inp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-127-740ba33bfa0e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m# Fetch the indices concerning the words in the sentence and pad the sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minp_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n\u001b[1;32m     15\u001b[0m                                                          \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length_inp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: ''"]}]},{"cell_type":"code","source":["code_to_text(testY[2], fr_tokenizer)"],"metadata":{"id":"LFWzaWQmxNoB","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1668376318423,"user_tz":360,"elapsed":265,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"019543e3-7b98-42b5-a240-ab4a3090b40e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<start> <end>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":115}]},{"cell_type":"code","source":["testY.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a3SpeNPc-c80","executionInfo":{"status":"ok","timestamp":1668376660867,"user_tz":360,"elapsed":1238,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"2ff4bd1b-1c86-465b-bc8e-319a6f2a0a70"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5000, 57)"]},"metadata":{},"execution_count":120}]},{"cell_type":"code","source":[],"metadata":{"id":"MTjpn_F1__j0"},"execution_count":null,"outputs":[]}]}