{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyP6uexpuT0Qey/UUP8amAem"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"_3EznmAC4f62","executionInfo":{"status":"ok","timestamp":1668966613317,"user_tz":360,"elapsed":2530,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from keras.preprocessing.text import Tokenizer\n","from keras_preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","import os\n","import string\n","import re\n","import pickle\n","from pickle import dump\n","import unicodedata\n","from unicodedata import normalize\n","import random"]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pWFhZxx-CFyv","executionInfo":{"status":"ok","timestamp":1668966648486,"user_tz":360,"elapsed":35173,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"0188441e-05e5-437d-8b79-4cead7813b23"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}]},{"cell_type":"code","source":["cd gdrive/MyDrive"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EMV9gGpbF5lC","executionInfo":{"status":"ok","timestamp":1668966648487,"user_tz":360,"elapsed":11,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"d31ad509-d9a9-481c-fe4f-89e1f8e9dff1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive\n"]}]},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_JMjfgGJ7f7t","executionInfo":{"status":"ok","timestamp":1666890316951,"user_tz":300,"elapsed":1014,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"3d9b71a8-526a-45a2-d558-d31ef3dafe96"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Oct 27 17:05:16 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    45W / 400W |      0MiB / 40536MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["# Dataset preprocessing"],"metadata":{"id":"DqFN2HRcRRED"}},{"cell_type":"markdown","source":["### Europarl dataset"],"metadata":{"id":"KZK4o7ujRsTV"}},{"cell_type":"code","source":["# load doc into memory\n","def load_doc(filename):\n","\tfile = open(filename, mode='rt', encoding='utf-8')\n","\ttext = file.read()\n","\tfile.close()\n","\treturn text\n"," \n","# split a loaded document into sentences\n","def to_sentences(doc):\n","\treturn doc.strip().split('\\n')\n"," \n","# clean a list of lines\n","def clean_lines(lines):\n","\tcleaned = list()\n","\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n","\ttable = str.maketrans('', '', string.punctuation)\n","\tfor line in lines:\n","\n","\t\tline = normalize('NFD', line).encode('ascii', 'ignore')\n","\t\tline = line.decode('UTF-8')\n","\n","\t\tline = line.split()\n","\n","\t\tline = [word.lower() for word in line]\n","\n","\t\tline = [word.translate(table) for word in line]\n","\n","\t\tline = [re_print.sub('', w) for w in line]\n","\n","\t\tline = [word for word in line if word.isalpha()]\n","\t\tline = ' '.join(line)\n","\t\tline = '<start> ' + line + ' <end>'\n","\t\t# store as string\n","\t\tcleaned.append(line)\n","\treturn cleaned\n"," \n","# save a list of clean sentences to file\n","def save_clean_sentences(sentences, filename):\n","\tdump(sentences, open(filename, 'wb'))\n","\tprint('Saved: %s' % filename)\n","\n","def load_datasets(filename):\n","    return pickle.load(open(filename, 'rb'))\n","\n","def produce_train_test(en, fr, ratio = 0.9, total_size = 5000):\n","    n_train = int(total_size * ratio)\n","    indexes = random.sample(range(total_size), n_train)\n","    trainX =  en[indexes]\n","    trainY = fr[indexes]\n","\n","    testX = en[[i for i in range(total_size) if i not in indexes]]\n","    testY = fr[[i for i in range(total_size) if i not in indexes]]\n","    return trainX, trainY, testX, testY\n","\n","# fit a tokenizer\n","def create_tokenizer(lines):\n","\ttokenizer = Tokenizer(filters = '')\n","\ttokenizer.fit_on_texts(lines)\n","\treturn tokenizer\n","\n","\n","# max sentence length\n","def max_length(lines):\n","\treturn max(len(line.split()) for line in lines)\n","\n","# encode and pad sequences\n","def encode_sequences(tokenizer, length, lines):\n","\tX = tokenizer.texts_to_sequences(lines)\n","\tX = pad_sequences(X, maxlen=length, padding='post')\n","\treturn X\n"," "],"metadata":{"id":"K15x31dSGcdw","executionInfo":{"status":"ok","timestamp":1668966660388,"user_tz":360,"elapsed":3,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# load English data\n","filename = 'europarl-v7.fr-en.en'\n","doc = load_doc(filename)\n","en_sentences = to_sentences(doc)\n","en_sentences = clean_lines(en_sentences)\n"," \n","# load French data\n","filename = 'europarl-v7.fr-en.fr'\n","doc = load_doc(filename)\n","fr_sentences = to_sentences(doc)\n","fr_sentences = clean_lines(fr_sentences)"],"metadata":{"id":"N_WSEGKdQ7er","colab":{"base_uri":"https://localhost:8080/","height":364},"executionInfo":{"status":"error","timestamp":1668879372260,"user_tz":360,"elapsed":5749,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"63e31fd4-8170-4f9a-f1fb-018c97e3f523"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-62b8b95caa83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load English data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'europarl-v7.fr-en.en'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0men_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0men_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-14567e3dd911>\u001b[0m in \u001b[0;36mload_doc\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# save cleaned dataset\n","save_clean_sentences(en_sentences, 'english.pkl')\n","save_clean_sentences(fr_sentences, 'french.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aJvVPsgeHLl4","executionInfo":{"status":"ok","timestamp":1666555965963,"user_tz":300,"elapsed":6049,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"6c8cfae1-6446-4e9d-e7e7-904c75a65a95"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved: english.pkl\n","Saved: french.pkl\n"]}]},{"cell_type":"code","source":["# load cleaned data to generate datasets\n","en_sentences = load_datasets('english.pkl')\n","fr_sentences = load_datasets('french.pkl')"],"metadata":{"id":"8d2El6q6fQHH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_size = 5000\n","en = np.array(en_sentences[:total_size])\n","fr = np.array(fr_sentences[:total_size])"],"metadata":{"id":"D17dvTQueky1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainX, trainY, testX, testY = produce_train_test(en, fr)"],"metadata":{"id":"tYOe1c44YIE0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### manythings dataset"],"metadata":{"id":"hDLFo0eXRf4b"}},{"cell_type":"code","source":["def preprocess_sentence(line):\n","\n","    re_print = re.compile('[^%s]' % re.escape(string.printable))\n","\n","    table = str.maketrans('', '', string.punctuation)\n","\n","    line = normalize('NFD', line).encode('ascii', 'ignore')\n","    line = line.decode('UTF-8')\n","\n","    line = line.split()\n","\n","    line = [word.lower() for word in line]\n","\n","    line = [word.translate(table) for word in line]\n","\n","    line = [re_print.sub('', w) for w in line]\n","\n","    line = [word for word in line if word.isalpha()]\n","    line = ' '.join(line)\n","    line = '<start> ' + line + ' <end>'\n","    return line\n","\n","import io\n","\n","# Create the Dataset\n","def create_dataset(path, num_examples):\n","    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n","\n","    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t', 2)[:-1]]  for l in lines[:num_examples]]\n","    return zip(*word_pairs)\n","\n","def encode_output(sequences, vocab_size):\n","\tylist = list()\n","\tfor sequence in sequences:\n","\t\tencoded = to_categorical(sequence, num_classes=vocab_size)\n","\t\tylist.append(encoded)\n","\ty = array(ylist)\n","\ty = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n","\treturn y"],"metadata":{"id":"WF_k3YokqEUH","executionInfo":{"status":"ok","timestamp":1668966748900,"user_tz":360,"elapsed":2,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["!unzip 'fra-eng.zip'"],"metadata":{"id":"ruFbwTjwREJv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668874445282,"user_tz":360,"elapsed":10014,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"0d4f333e-b380-436e-dd89-f17be3c0b460"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  fra-eng.zip\n","replace _about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "]}]},{"cell_type":"code","source":["path_to_file = \"fra.txt\""],"metadata":{"id":"dep5PaXuREVj","executionInfo":{"status":"ok","timestamp":1668966751175,"user_tz":360,"elapsed":208,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["en, fr = create_dataset(path_to_file, None)\n","trainX, trainY, testX, testY = produce_train_test(np.array(en[:50000]), np.array(fr[:50000]), total_size = 50000)"],"metadata":{"id":"JJsXCdA6nynA","executionInfo":{"status":"ok","timestamp":1668966812797,"user_tz":360,"elapsed":61122,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["### Create tokenizer "],"metadata":{"id":"DqRyGLhIRYZj"}},{"cell_type":"code","source":["en_tokenizer = create_tokenizer(en)\n","en_vocab_size = len(en_tokenizer.word_index) + 1\n","en_length = max_length(en)\n","print('English Vocabulary Size: %d' % en_vocab_size)\n","print('English Max Length: %d' % (en_length))\n","\n","fr_tokenizer = create_tokenizer(fr)\n","fr_vocab_size = len(fr_tokenizer.word_index) + 1\n","fr_length = max_length(fr)\n","print('French Vocabulary Size: %d' % fr_vocab_size)\n","print('French Max Length: %d' % (fr_length))\n"," \n","# prepare training data\n","trainX = encode_sequences(en_tokenizer, en_length, trainX)\n","trainY = encode_sequences(fr_tokenizer, fr_length, trainY)\n","\n","# prepare validation data\n","testX = encode_sequences(en_tokenizer, en_length, testX)\n","testY = encode_sequences(en_tokenizer, fr_length, testY)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OwhjH4Wgfzy1","executionInfo":{"status":"ok","timestamp":1668966846078,"user_tz":360,"elapsed":4274,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"d54d1399-66bb-4f6c-9316-9523dd9f185d"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["English Vocabulary Size: 15826\n","English Max Length: 49\n","French Vocabulary Size: 30186\n","French Max Length: 57\n"]}]},{"cell_type":"code","source":["trainX.shape, trainY.shape, testX.shape, testY.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wBL6O2cmgtPd","executionInfo":{"status":"ok","timestamp":1668879446289,"user_tz":360,"elapsed":12,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"c9cc693e-3eee-4784-a2ce-6f5d20aa8578"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((45000, 49), (45000, 57), (5000, 49), (5000, 57))"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["def convert(lang, tensor):\n","  for t in tensor:\n","    if t != 0:\n","      print (\"%d ----> %s\" % (t, lang.index_word[t]))\n","      \n","print (\"Input Language; index to word mapping\")\n","convert(en_tokenizer, trainX[0])\n","print ()\n","print (\"Target Language; index to word mapping\")\n","convert(fr_tokenizer, trainY[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3CL1zkgsavIP","executionInfo":{"status":"ok","timestamp":1668879446290,"user_tz":360,"elapsed":11,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"13ad4617-4f3c-4ce3-d307-5bd95345cb44"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input Language; index to word mapping\n","1 ----> <start>\n","3 ----> i\n","53 ----> cant\n","180 ----> stop\n","49 ----> him\n","2 ----> <end>\n","\n","Target Language; index to word mapping\n","1 ----> <start>\n","3 ----> je\n","9 ----> ne\n","65 ----> peux\n","6 ----> pas\n","10 ----> le\n","6938 ----> stopper\n","2 ----> <end>\n"]}]},{"cell_type":"markdown","source":["# Model Parameters"],"metadata":{"id":"ZM4rjYGnavkU"}},{"cell_type":"code","source":["BUFFER_SIZE = len(trainX)\n","BATCH_SIZE = 64\n","steps_per_epoch = len(trainY)//BATCH_SIZE\n","embedding_dim = 256\n","units = 512\n","architecture = 'gru' # gru, simple RNN"],"metadata":{"id":"5iVIC442LJ3o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = tf.data.Dataset.from_tensor_slices((trainX, trainY)).shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"],"metadata":{"id":"tp5Iw_n0KNLm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["example_input_batch, example_target_batch = next(iter(dataset))\n","example_input_batch.shape, example_target_batch.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fcPqSjSfLa9S","executionInfo":{"status":"ok","timestamp":1668355443613,"user_tz":360,"elapsed":6,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"ce72feed-f17c-4cb5-c239-51d797cb24fe"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([64, 49]), TensorShape([64, 57]))"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["# Simple NMT model"],"metadata":{"id":"RvcFd9kXHbu5"}},{"cell_type":"code","source":["from keras.utils.vis_utils import plot_model\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense, Embedding, RepeatVector, TimeDistributed, SimpleRNN\n","from keras.callbacks import ModelCheckpoint"],"metadata":{"id":"6OvycN1uibDv","executionInfo":{"status":"ok","timestamp":1668966675648,"user_tz":360,"elapsed":412,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def build_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n","    model = Sequential()\n","    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n","    model.add(LSTM(units))\n","    model.add(RepeatVector(out_timesteps))\n","    model.add(LSTM(units, return_sequences=True))\n","    model.add(Dense(out_vocab, activation='softmax'))\n","    return model"],"metadata":{"id":"qN2_zcv4hsd4","executionInfo":{"status":"ok","timestamp":1668966675649,"user_tz":360,"elapsed":2,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["model = build_model(en_vocab_size, fr_vocab_size, en_length, fr_length, 512)\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n","print(model.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FMtPK7OgiTPc","executionInfo":{"status":"ok","timestamp":1668966855021,"user_tz":360,"elapsed":3911,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"ac00c68c-69a3-46a4-ddd3-aa0f428f98c6"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 49, 512)           8102912   \n","                                                                 \n"," lstm (LSTM)                 (None, 512)               2099200   \n","                                                                 \n"," repeat_vector (RepeatVector  (None, 57, 512)          0         \n"," )                                                               \n","                                                                 \n"," lstm_1 (LSTM)               (None, 57, 512)           2099200   \n","                                                                 \n"," dense (Dense)               (None, 57, 30186)         15485418  \n","                                                                 \n","=================================================================\n","Total params: 27,786,730\n","Trainable params: 27,786,730\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["filename = 'model.h1.24_jan_20'\n","checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n","\n","history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n","          epochs=30, batch_size=512, \n","          validation_split = 0.05,\n","          callbacks=[checkpoint], verbose=1)"],"metadata":{"id":"mxu_1lAsich0","colab":{"base_uri":"https://localhost:8080/","height":239},"outputId":"f86a5d54-d2f3-453b-9579-ac3f59e664ed","executionInfo":{"status":"error","timestamp":1668966741225,"user_tz":360,"elapsed":364,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}}},"execution_count":9,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-882999f202f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n\u001b[0m\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.plot(history.history['loss'], 'bo')\n","# plt.plot(history.history['val_loss'])\n","plt.legend(['train','validation'])\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"q27BsBkuw3iO","executionInfo":{"status":"ok","timestamp":1668894475283,"user_tz":360,"elapsed":343,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"8f81e1c7-cf59-47e7-b78f-12fee59a0b29"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["model.save('translate_en_fr.h5')"],"metadata":{"id":"L_5ndaPUHY7d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def word_for_id(integer, tokenizer):\n","\tfor word, index in tokenizer.word_index.items():\n","\t\tif index == integer:\n","\t\t\treturn word\n","\treturn None\n"," \n","# generate target given source sequence\n","def predict_sequence(model, tokenizer, source):\n","    source = source.reshape((1, source.shape[0]))\n","    prediction = model.predict(source, verbose=0)[0]\n","    integers = [np.argmax(vector) for vector in prediction]\n","    target = list()\n","    input = ''\n","    for i in integers:\n","        word = word_for_id(i, tokenizer)\n","        if word is None:\n","            break\n","        target.append(word)\n","    return ' '.join(target)"],"metadata":{"id":"uL-aIYW7iwhi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["source = trainX[0]\n","predict_sequence(model, fr_tokenizer, source)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"hbqgEJtsiyJw","executionInfo":{"status":"ok","timestamp":1666902091834,"user_tz":300,"elapsed":79,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"d8fe3605-3f6e-4e3b-93d4-1ca0e4f992a3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<start> tu etes sympa . <end>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":53}]},{"cell_type":"markdown","source":["# Encoder class"],"metadata":{"id":"GiZRSIoiHfTZ"}},{"cell_type":"code","source":["# Encoder class\n","class Encoder(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n","        super(Encoder, self).__init__()\n","        self.batch_sz = batch_sz\n","        self.enc_units = enc_units\n","\n","        # Embed the vocab to a dense embedding \n","        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","\n","        # GRU Layer\n","        # glorot_uniform: Initializer for the recurrent_kernel weights matrix, \n","        # used for the linear transformation of the recurrent state\n","        if architecture == 'gru':\n","            self.rnn = tf.keras.layers.GRU(self.enc_units,\n","                                            return_sequences=True,\n","                                            return_state=True,\n","                                            recurrent_initializer='glorot_uniform')\n","        if architecture == 'rnn':\n","            self.rnn = tf.keras.layers.SimpleRNN(self.enc_units,\n","                                            return_sequences=True,\n","                                            return_state=True,\n","                                            recurrent_initializer='glorot_uniform')     \n","        self.rnn = tf.keras.layers.Bidirectional(self.rnn)\n","\n","    # Encoder network comprises an Embedding layer followed by a GRU layer\n","    def call(self, x, hidden):\n","        x = self.embedding(x)\n","        output, forward_state, backward_state = self.rnn(x, initial_state=hidden)\n","        return output, tf.keras.layers.Concatenate()([forward_state, backward_state])\n","\n","    # To initialize the hidden state\n","    def initialize_hidden_state(self):\n","        return [tf.zeros((self.batch_sz, self.enc_units)) for i in range(2)]"],"metadata":{"id":"ol5o64Ou_Wf_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder = Encoder(en_vocab_size, embedding_dim, units, BATCH_SIZE)\n","\n","sample_hidden = encoder.initialize_hidden_state()\n","sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n","\n","print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n","print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZamiUpQ-LgJ_","executionInfo":{"status":"ok","timestamp":1668360197950,"user_tz":360,"elapsed":6,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"044ee690-7c3f-471b-dd33-d90c7678c9fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoder output shape: (batch size, sequence length, units) (64, 49, 1024)\n","Encoder Hidden state shape: (batch size, units) (64, 1024)\n"]}]},{"cell_type":"markdown","source":["# Attention layer"],"metadata":{"id":"aTUJxoQZH3A4"}},{"cell_type":"code","source":["# Attention Mechanism\n","class Attention(tf.keras.layers.Layer):\n","  def __init__(self, units):\n","    super(Attention, self).__init__()\n","    self.W1 = tf.keras.layers.Dense(units)\n","    self.W2 = tf.keras.layers.Dense(units)\n","    self.V = tf.keras.layers.Dense(1)\n","\n","  def call(self, query, values):\n","    # query hidden state shape == (batch_size, hidden size)\n","    # values shape == (batch_size, max_len, hidden size)\n","\n","    # we are doing this to broadcast addition along the time axis to calculate the score\n","    # query_with_time_axis shape == (batch_size, 1, hidden size)\n","    query_with_time_axis = tf.expand_dims(query, 1)\n","\n","    # score shape == (batch_size, max_length, 1)\n","    # we get 1 at the last axis because we are applying score to self.V\n","    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n","    score = self.V(tf.nn.tanh(\n","        self.W1(query_with_time_axis) + self.W2(values)))\n","\n","    # attention_weights shape == (batch_size, max_length, 1)\n","    attention_weights = tf.nn.softmax(score, axis=1)\n","\n","    # context_vector shape after sum == (batch_size, hidden_size)\n","    context_vector = attention_weights * values\n","    context_vector = tf.reduce_sum(context_vector, axis=1)\n","\n","    return context_vector, attention_weights"],"metadata":{"id":"e5wKEbDeH2hB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["attention_layer = Attention(10)\n","attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n","\n","print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n","print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"],"metadata":{"id":"7_YOjEzZL2LN","executionInfo":{"status":"ok","timestamp":1668360202462,"user_tz":360,"elapsed":2,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b2f23f7f-c90b-4e85-d0a1-b7ccf3e9395c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Attention result shape: (batch size, units) (64, 1024)\n","Attention weights shape: (batch_size, sequence_length, 1) (64, 49, 1)\n"]}]},{"cell_type":"markdown","source":["# Decoder Class"],"metadata":{"id":"mfTebVydH8eO"}},{"cell_type":"code","source":["# Decoder class\n","class Decoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n","    super(Decoder, self).__init__()\n","    self.batch_sz = batch_sz\n","    self.dec_units = dec_units\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.SimpleRNN(self.dec_units,\n","                                   return_sequences=True,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","    self.fc = tf.keras.layers.Dense(vocab_size)\n","\n","    # Used for attention\n","    self.attention = Attention(self.dec_units)\n","\n","  def call(self, x, hidden, enc_output):\n","    # x shape == (batch_size, 1)\n","    # hidden shape == (batch_size, max_length)\n","    # enc_output shape == (batch_size, max_length, hidden_size)\n","\n","    # context_vector shape == (batch_size, hidden_size)\n","    # attention_weights shape == (batch_size, max_length, 1)\n","    context_vector, attention_weights = self.attention(hidden, enc_output)\n","\n","    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n","    x = self.embedding(x)\n","\n","    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n","    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n","\n","    # passing the concatenated vector to the GRU\n","    output, state = self.gru(x)\n","\n","    # output shape == (batch_size * 1, hidden_size)\n","    output = tf.reshape(output, (-1, output.shape[2]))\n","\n","    # output shape == (batch_size, vocab)\n","    x = self.fc(output)\n","\n","    return x, state, attention_weights"],"metadata":{"id":"0Y3BMguw_-JD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["decoder = Decoder(fr_vocab_size, embedding_dim, units * 2, BATCH_SIZE)\n","\n","sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n","                                      sample_hidden, sample_output)\n","\n","print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"],"metadata":{"id":"IqzCT8xVL_3k","executionInfo":{"status":"ok","timestamp":1668360206964,"user_tz":360,"elapsed":4,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"666c9cd8-26b1-4c51-e98e-aa025414f0c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Decoder output shape: (batch_size, vocab size) (64, 30186)\n"]}]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"gwyUNfIQP20t"}},{"cell_type":"code","source":["# Initialize optimizer and loss functions\n","optimizer = tf.keras.optimizers.Adam()\n","\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')\n","\n","# Loss function\n","def loss_function(real, pred):\n","\n","  # Take care of the padding. Not all sequences are of equal length.\n","  # If there's a '0' in the sequence, the loss is being nullified\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  loss_ = loss_object(real, pred)\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype)\n","  loss_ *= mask\n","\n","  return tf.reduce_mean(loss_)"],"metadata":{"id":"mkibV-bzMAMS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","checkpoint_dir = './birnn_training_checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n","                                 encoder=encoder,\n","                                 decoder=decoder)"],"metadata":{"id":"mL-Y6lXWP4yD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@tf.function\n","def train_step(inp, targ, enc_hidden):\n","  loss = 0\n","\n","  # tf.GradientTape() -- record operations for automatic differentiation\n","  with tf.GradientTape() as tape:\n","    enc_output, enc_hidden = encoder(inp, enc_hidden)\n","\n","    # dec_hidden is used by attention, hence is the same enc_hidden\n","    dec_hidden = enc_hidden\n","\n","    # <start> token is the initial decoder input\n","    dec_input = tf.expand_dims([fr_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n","\n","    # Teacher forcing - feeding the target as the next input\n","    for t in range(1, targ.shape[1]):\n","\n","      # Pass enc_output to the decoder\n","      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n","\n","      # Compute the loss\n","      loss += loss_function(targ[:, t], predictions)\n","\n","      # Use teacher forcing\n","      dec_input = tf.expand_dims(targ[:, t], 1)\n","\n","  # As this function is called per batch, compute the batch_loss\n","  batch_loss = (loss / int(targ.shape[1]))\n","\n","  # Get the model's variables\n","  variables = encoder.trainable_variables + decoder.trainable_variables\n","\n","  # Compute the gradients\n","  gradients = tape.gradient(loss, variables)\n","\n","  # Update the variables of the model/network\n","  optimizer.apply_gradients(zip(gradients, variables))\n","\n","  return batch_loss"],"metadata":{"id":"MNiTqwl6P7mt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","EPOCHS = 30\n","history = []\n","# Training loop\n","for epoch in range(EPOCHS):\n","  start = time.time()\n","\n","  # Initialize the hidden state\n","  enc_hidden = encoder.initialize_hidden_state()\n","  total_loss = 0\n","\n","  # Loop through the dataset\n","  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n","\n","    # Call the train method\n","    batch_loss = train_step(inp, targ, enc_hidden)\n","\n","    # Compute the loss (per batch)\n","    total_loss += batch_loss\n","\n","    if batch % 100 == 0:\n","      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n","                                                   batch,\n","                                                   batch_loss.numpy()))\n","  # Save (checkpoint) the model every 2 epochs\n","  if (epoch + 1) % 2 == 0:\n","    checkpoint.save(file_prefix = checkpoint_prefix)\n","\n","  # Output the loss observed until that epoch\n","  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n","                                      total_loss / steps_per_epoch))\n","  \n","  history.append(total_loss / steps_per_epoch)\n","  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"],"metadata":{"id":"RM3qVshkQAbR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668375078214,"user_tz":360,"elapsed":14854549,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"b5cad168-e7ed-4670-9916-3a10095069c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 Batch 0 Loss 0.8851\n","Epoch 1 Batch 100 Loss 0.5696\n","Epoch 1 Batch 200 Loss 0.5710\n","Epoch 1 Batch 300 Loss 0.5763\n","Epoch 1 Batch 400 Loss 0.5578\n","Epoch 1 Batch 500 Loss 0.5520\n","Epoch 1 Batch 600 Loss 0.5726\n","Epoch 1 Batch 700 Loss 0.5415\n","Epoch 1 Loss 0.5703\n","Time taken for 1 epoch 528.5638115406036 sec\n","\n","Epoch 2 Batch 0 Loss 0.5422\n","Epoch 2 Batch 100 Loss 0.5835\n","Epoch 2 Batch 200 Loss 0.5216\n","Epoch 2 Batch 300 Loss 0.5703\n","Epoch 2 Batch 400 Loss 0.5904\n","Epoch 2 Batch 500 Loss 0.5923\n","Epoch 2 Batch 600 Loss 0.5470\n","Epoch 2 Batch 700 Loss 0.5334\n","Epoch 2 Loss 0.5625\n","Time taken for 1 epoch 482.5690791606903 sec\n","\n","Epoch 3 Batch 0 Loss 0.5635\n","Epoch 3 Batch 100 Loss 0.5327\n","Epoch 3 Batch 200 Loss 0.5359\n","Epoch 3 Batch 300 Loss 0.5629\n","Epoch 3 Batch 400 Loss 0.5923\n","Epoch 3 Batch 500 Loss 0.5793\n","Epoch 3 Batch 600 Loss 0.5623\n","Epoch 3 Batch 700 Loss 0.5913\n","Epoch 3 Loss 0.5656\n","Time taken for 1 epoch 481.31429958343506 sec\n","\n","Epoch 4 Batch 0 Loss 0.5635\n","Epoch 4 Batch 100 Loss 0.5526\n","Epoch 4 Batch 200 Loss 0.5418\n","Epoch 4 Batch 300 Loss 0.5707\n","Epoch 4 Batch 400 Loss 0.5673\n","Epoch 4 Batch 500 Loss 0.5649\n","Epoch 4 Batch 600 Loss 0.5807\n","Epoch 4 Batch 700 Loss 0.5798\n","Epoch 4 Loss 0.5643\n","Time taken for 1 epoch 484.21072220802307 sec\n","\n","Epoch 5 Batch 0 Loss 0.5828\n","Epoch 5 Batch 100 Loss 0.5523\n","Epoch 5 Batch 200 Loss 0.5410\n","Epoch 5 Batch 300 Loss 0.5504\n","Epoch 5 Batch 400 Loss 0.5781\n","Epoch 5 Batch 500 Loss 0.4519\n","Epoch 5 Batch 600 Loss 0.4828\n","Epoch 5 Batch 700 Loss 0.4189\n","Epoch 5 Loss 0.5339\n","Time taken for 1 epoch 484.7914719581604 sec\n","\n","Epoch 6 Batch 0 Loss 0.4476\n","Epoch 6 Batch 100 Loss 0.3987\n","Epoch 6 Batch 200 Loss 0.3992\n","Epoch 6 Batch 300 Loss 0.3498\n","Epoch 6 Batch 400 Loss 0.3604\n","Epoch 6 Batch 500 Loss 0.3395\n","Epoch 6 Batch 600 Loss 0.3463\n","Epoch 6 Batch 700 Loss 0.3014\n","Epoch 6 Loss 0.3607\n","Time taken for 1 epoch 493.21798300743103 sec\n","\n","Epoch 7 Batch 0 Loss 0.2633\n","Epoch 7 Batch 100 Loss 0.2801\n","Epoch 7 Batch 200 Loss 0.2759\n","Epoch 7 Batch 300 Loss 0.2685\n","Epoch 7 Batch 400 Loss 0.2432\n","Epoch 7 Batch 500 Loss 0.2473\n","Epoch 7 Batch 600 Loss 0.2348\n","Epoch 7 Batch 700 Loss 0.2338\n","Epoch 7 Loss 0.2558\n","Time taken for 1 epoch 493.47838735580444 sec\n","\n","Epoch 8 Batch 0 Loss 0.1818\n","Epoch 8 Batch 100 Loss 0.1894\n","Epoch 8 Batch 200 Loss 0.1931\n","Epoch 8 Batch 300 Loss 0.1824\n","Epoch 8 Batch 400 Loss 0.1995\n","Epoch 8 Batch 500 Loss 0.1844\n","Epoch 8 Batch 600 Loss 0.1808\n","Epoch 8 Batch 700 Loss 0.1674\n","Epoch 8 Loss 0.1838\n","Time taken for 1 epoch 496.485639333725 sec\n","\n","Epoch 9 Batch 0 Loss 0.1517\n","Epoch 9 Batch 100 Loss 0.1475\n","Epoch 9 Batch 200 Loss 0.1242\n","Epoch 9 Batch 300 Loss 0.1392\n","Epoch 9 Batch 400 Loss 0.1321\n","Epoch 9 Batch 500 Loss 0.1287\n","Epoch 9 Batch 600 Loss 0.1252\n","Epoch 9 Batch 700 Loss 0.1314\n","Epoch 9 Loss 0.1364\n","Time taken for 1 epoch 494.36444330215454 sec\n","\n","Epoch 10 Batch 0 Loss 0.0907\n","Epoch 10 Batch 100 Loss 0.0988\n","Epoch 10 Batch 200 Loss 0.1022\n","Epoch 10 Batch 300 Loss 0.1101\n","Epoch 10 Batch 400 Loss 0.1195\n","Epoch 10 Batch 500 Loss 0.1247\n","Epoch 10 Batch 600 Loss 0.0980\n","Epoch 10 Batch 700 Loss 0.0960\n","Epoch 10 Loss 0.1076\n","Time taken for 1 epoch 495.80515718460083 sec\n","\n","Epoch 11 Batch 0 Loss 0.0765\n","Epoch 11 Batch 100 Loss 0.0861\n","Epoch 11 Batch 200 Loss 0.0907\n","Epoch 11 Batch 300 Loss 0.0843\n","Epoch 11 Batch 400 Loss 0.0969\n","Epoch 11 Batch 500 Loss 0.0957\n","Epoch 11 Batch 600 Loss 0.1017\n","Epoch 11 Batch 700 Loss 0.1045\n","Epoch 11 Loss 0.0904\n","Time taken for 1 epoch 494.5964195728302 sec\n","\n","Epoch 12 Batch 0 Loss 0.0708\n","Epoch 12 Batch 100 Loss 0.0708\n","Epoch 12 Batch 200 Loss 0.0709\n","Epoch 12 Batch 300 Loss 0.0851\n","Epoch 12 Batch 400 Loss 0.0762\n","Epoch 12 Batch 500 Loss 0.0861\n","Epoch 12 Batch 600 Loss 0.0940\n","Epoch 12 Batch 700 Loss 0.0773\n","Epoch 12 Loss 0.0795\n","Time taken for 1 epoch 497.3116023540497 sec\n","\n","Epoch 13 Batch 0 Loss 0.0649\n","Epoch 13 Batch 100 Loss 0.0656\n","Epoch 13 Batch 200 Loss 0.0783\n","Epoch 13 Batch 300 Loss 0.0720\n","Epoch 13 Batch 400 Loss 0.0927\n","Epoch 13 Batch 500 Loss 0.0702\n","Epoch 13 Batch 600 Loss 0.0916\n","Epoch 13 Batch 700 Loss 0.0897\n","Epoch 13 Loss 0.0725\n","Time taken for 1 epoch 494.76802372932434 sec\n","\n","Epoch 14 Batch 0 Loss 0.0557\n","Epoch 14 Batch 100 Loss 0.0673\n","Epoch 14 Batch 200 Loss 0.0566\n","Epoch 14 Batch 300 Loss 0.0663\n","Epoch 14 Batch 400 Loss 0.0590\n","Epoch 14 Batch 500 Loss 0.0761\n","Epoch 14 Batch 600 Loss 0.0715\n","Epoch 14 Batch 700 Loss 0.0862\n","Epoch 14 Loss 0.0675\n","Time taken for 1 epoch 496.6894829273224 sec\n","\n","Epoch 15 Batch 0 Loss 0.0529\n","Epoch 15 Batch 100 Loss 0.0604\n","Epoch 15 Batch 200 Loss 0.0575\n","Epoch 15 Batch 300 Loss 0.0741\n","Epoch 15 Batch 400 Loss 0.0524\n","Epoch 15 Batch 500 Loss 0.0685\n","Epoch 15 Batch 600 Loss 0.0806\n","Epoch 15 Batch 700 Loss 0.0750\n","Epoch 15 Loss 0.0643\n","Time taken for 1 epoch 495.3743054866791 sec\n","\n","Epoch 16 Batch 0 Loss 0.0575\n","Epoch 16 Batch 100 Loss 0.0539\n","Epoch 16 Batch 200 Loss 0.0502\n","Epoch 16 Batch 300 Loss 0.0395\n","Epoch 16 Batch 400 Loss 0.0519\n","Epoch 16 Batch 500 Loss 0.0589\n","Epoch 16 Batch 600 Loss 0.0698\n","Epoch 16 Batch 700 Loss 0.0898\n","Epoch 16 Loss 0.0621\n","Time taken for 1 epoch 496.29199290275574 sec\n","\n","Epoch 17 Batch 0 Loss 0.0534\n","Epoch 17 Batch 100 Loss 0.0576\n","Epoch 17 Batch 200 Loss 0.0516\n","Epoch 17 Batch 300 Loss 0.0520\n","Epoch 17 Batch 400 Loss 0.0546\n","Epoch 17 Batch 500 Loss 0.0645\n","Epoch 17 Batch 600 Loss 0.0563\n","Epoch 17 Batch 700 Loss 0.0648\n","Epoch 17 Loss 0.0607\n","Time taken for 1 epoch 495.104407787323 sec\n","\n","Epoch 18 Batch 0 Loss 0.0513\n","Epoch 18 Batch 100 Loss 0.0388\n","Epoch 18 Batch 200 Loss 0.0479\n","Epoch 18 Batch 300 Loss 0.0591\n","Epoch 18 Batch 400 Loss 0.0540\n","Epoch 18 Batch 500 Loss 0.0653\n","Epoch 18 Batch 600 Loss 0.0738\n","Epoch 18 Batch 700 Loss 0.0679\n","Epoch 18 Loss 0.0597\n","Time taken for 1 epoch 496.2592260837555 sec\n","\n","Epoch 19 Batch 0 Loss 0.0517\n","Epoch 19 Batch 100 Loss 0.0554\n","Epoch 19 Batch 200 Loss 0.0611\n","Epoch 19 Batch 300 Loss 0.0414\n","Epoch 19 Batch 400 Loss 0.0775\n","Epoch 19 Batch 500 Loss 0.0806\n","Epoch 19 Batch 600 Loss 0.0650\n","Epoch 19 Batch 700 Loss 0.0810\n","Epoch 19 Loss 0.0583\n","Time taken for 1 epoch 495.0686674118042 sec\n","\n","Epoch 20 Batch 0 Loss 0.0435\n","Epoch 20 Batch 100 Loss 0.0435\n","Epoch 20 Batch 200 Loss 0.0551\n","Epoch 20 Batch 300 Loss 0.0589\n","Epoch 20 Batch 400 Loss 0.0649\n","Epoch 20 Batch 500 Loss 0.0554\n","Epoch 20 Batch 600 Loss 0.0564\n","Epoch 20 Batch 700 Loss 0.0651\n","Epoch 20 Loss 0.0575\n","Time taken for 1 epoch 497.02091789245605 sec\n","\n","Epoch 21 Batch 0 Loss 0.0492\n","Epoch 21 Batch 100 Loss 0.0425\n","Epoch 21 Batch 200 Loss 0.0506\n","Epoch 21 Batch 300 Loss 0.0483\n","Epoch 21 Batch 400 Loss 0.0512\n","Epoch 21 Batch 500 Loss 0.0530\n","Epoch 21 Batch 600 Loss 0.0616\n","Epoch 21 Batch 700 Loss 0.0660\n","Epoch 21 Loss 0.0570\n","Time taken for 1 epoch 494.9774730205536 sec\n","\n","Epoch 22 Batch 0 Loss 0.0533\n","Epoch 22 Batch 100 Loss 0.0396\n","Epoch 22 Batch 200 Loss 0.0502\n","Epoch 22 Batch 300 Loss 0.0550\n","Epoch 22 Batch 400 Loss 0.0606\n","Epoch 22 Batch 500 Loss 0.0619\n","Epoch 22 Batch 600 Loss 0.0719\n","Epoch 22 Batch 700 Loss 0.0812\n","Epoch 22 Loss 0.0568\n","Time taken for 1 epoch 496.7974536418915 sec\n","\n","Epoch 23 Batch 0 Loss 0.0372\n","Epoch 23 Batch 100 Loss 0.0576\n","Epoch 23 Batch 200 Loss 0.0484\n","Epoch 23 Batch 300 Loss 0.0512\n","Epoch 23 Batch 400 Loss 0.0589\n","Epoch 23 Batch 500 Loss 0.0546\n","Epoch 23 Batch 600 Loss 0.0634\n","Epoch 23 Batch 700 Loss 0.0772\n","Epoch 23 Loss 0.0562\n","Time taken for 1 epoch 494.8831465244293 sec\n","\n","Epoch 24 Batch 0 Loss 0.0639\n","Epoch 24 Batch 100 Loss 0.0568\n","Epoch 24 Batch 200 Loss 0.0485\n","Epoch 24 Batch 300 Loss 0.0523\n","Epoch 24 Batch 400 Loss 0.0696\n","Epoch 24 Batch 500 Loss 0.0739\n","Epoch 24 Batch 600 Loss 0.0484\n","Epoch 24 Batch 700 Loss 0.0724\n","Epoch 24 Loss 0.0559\n","Time taken for 1 epoch 496.5536632537842 sec\n","\n","Epoch 25 Batch 0 Loss 0.0413\n","Epoch 25 Batch 100 Loss 0.0733\n","Epoch 25 Batch 200 Loss 0.0396\n","Epoch 25 Batch 300 Loss 0.0528\n","Epoch 25 Batch 400 Loss 0.0565\n","Epoch 25 Batch 500 Loss 0.0654\n","Epoch 25 Batch 600 Loss 0.0594\n","Epoch 25 Batch 700 Loss 0.0772\n","Epoch 25 Loss 0.0555\n","Time taken for 1 epoch 495.0854687690735 sec\n","\n","Epoch 26 Batch 0 Loss 0.0493\n","Epoch 26 Batch 100 Loss 0.0553\n","Epoch 26 Batch 200 Loss 0.0557\n","Epoch 26 Batch 300 Loss 0.0721\n","Epoch 26 Batch 400 Loss 0.0462\n","Epoch 26 Batch 500 Loss 0.0313\n","Epoch 26 Batch 600 Loss 0.0556\n","Epoch 26 Batch 700 Loss 0.0652\n","Epoch 26 Loss 0.0555\n","Time taken for 1 epoch 497.275160074234 sec\n","\n","Epoch 27 Batch 0 Loss 0.0607\n","Epoch 27 Batch 100 Loss 0.0530\n","Epoch 27 Batch 200 Loss 0.0386\n","Epoch 27 Batch 300 Loss 0.0529\n","Epoch 27 Batch 400 Loss 0.0460\n","Epoch 27 Batch 500 Loss 0.0724\n","Epoch 27 Batch 600 Loss 0.0753\n","Epoch 27 Batch 700 Loss 0.0755\n","Epoch 27 Loss 0.0552\n","Time taken for 1 epoch 494.97207260131836 sec\n","\n","Epoch 28 Batch 0 Loss 0.0436\n","Epoch 28 Batch 100 Loss 0.0481\n","Epoch 28 Batch 200 Loss 0.0415\n","Epoch 28 Batch 300 Loss 0.0571\n","Epoch 28 Batch 400 Loss 0.0485\n","Epoch 28 Batch 500 Loss 0.0673\n","Epoch 28 Batch 600 Loss 0.0605\n","Epoch 28 Batch 700 Loss 0.0638\n","Epoch 28 Loss 0.0552\n","Time taken for 1 epoch 497.44697546958923 sec\n","\n","Epoch 29 Batch 0 Loss 0.0444\n","Epoch 29 Batch 100 Loss 0.0516\n","Epoch 29 Batch 200 Loss 0.0266\n","Epoch 29 Batch 300 Loss 0.0454\n","Epoch 29 Batch 400 Loss 0.0639\n","Epoch 29 Batch 500 Loss 0.0491\n","Epoch 29 Batch 600 Loss 0.0716\n","Epoch 29 Batch 700 Loss 0.0487\n","Epoch 29 Loss 0.0546\n","Time taken for 1 epoch 494.88418555259705 sec\n","\n","Epoch 30 Batch 0 Loss 0.0315\n","Epoch 30 Batch 100 Loss 0.0446\n","Epoch 30 Batch 200 Loss 0.0482\n","Epoch 30 Batch 300 Loss 0.0393\n","Epoch 30 Batch 400 Loss 0.0558\n","Epoch 30 Batch 500 Loss 0.0671\n","Epoch 30 Batch 600 Loss 0.0916\n","Epoch 30 Batch 700 Loss 0.0556\n","Epoch 30 Loss 0.0549\n","Time taken for 1 epoch 498.15559005737305 sec\n","\n"]}]},{"cell_type":"markdown","source":["# Evaluation"],"metadata":{"id":"AsyjZbrIbyXh"}},{"cell_type":"code","source":["def plot_training(history):\n","    loss = history\n","    epochs = range(1, len(history) + 1)\n","    \n","    # Plot training and validation loss\n","    plt.plot(epochs, loss, 'bo', label = 'training loss')\n","    plt.title('training loss')\n","    plt.legend()\n"],"metadata":{"id":"afXEh0I3_Ygq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_training(history)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"id":"_y7QDlvX_Zi7","executionInfo":{"status":"ok","timestamp":1668376575792,"user_tz":360,"elapsed":6,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"c9f6b9a4-4fbb-45dc-f061-08d36c0b250b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["import numpy as np\n","\n","# Evaluate function -- similar to the training loop\n","def evaluate(sentence, max_length_inp, max_length_targ, inp_lang, targ_lang):\n","\n","  # Attention plot (to be plotted later on) -- initialized with max_lengths of both target and input\n","  attention_plot = np.zeros((max_length_targ, max_length_inp))\n","\n","  # Preprocess the sentence given\n","  sentence = preprocess_sentence(sentence)\n","\n","  # Fetch the indices concerning the words in the sentence and pad the sequence\n","  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n","  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n","                                                         maxlen=max_length_inp,\n","                                                         padding='post')\n","  # Convert the inputs to tensors\n","  inputs = tf.convert_to_tensor(inputs)\n","\n","  result = ''\n","\n","  hidden = [tf.zeros((1, units)) for i in range(2)]\n","  enc_out, enc_hidden = encoder(inputs, hidden)\n","\n","  dec_hidden = enc_hidden\n","  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n","\n","  # Loop until the max_length is reached for the target lang (ENGLISH)\n","  for t in range(max_length_targ):\n","    predictions, dec_hidden, attention_weights = decoder(dec_input,\n","                                                         dec_hidden,\n","                                                         enc_out)\n","\n","    # Store the attention weights to plot later on\n","    attention_weights = tf.reshape(attention_weights, (-1, ))\n","    attention_plot[t] = attention_weights.numpy()\n","\n","    # Get the prediction with the maximum attention\n","    predicted_id = tf.argmax(predictions[0]).numpy()\n","\n","    # Append the token to the result\n","    result += targ_lang.index_word[predicted_id] + ' '\n","\n","    # If <end> token is reached, return the result, input, and attention plot\n","    if targ_lang.index_word[predicted_id] == '<end>':\n","      return result, sentence, attention_plot\n","\n","    # The predicted ID is fed back into the model\n","    dec_input = tf.expand_dims([predicted_id], 0)\n","\n","  return result, sentence, attention_plot"],"metadata":{"id":"87W9T43zaHYE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","\n","# Function for plotting the attention weights\n","def plot_attention(attention, sentence, predicted_sentence):\n","  fig = plt.figure(figsize=(10,10))\n","  ax = fig.add_subplot(1, 1, 1)\n","  ax.matshow(attention, cmap='viridis')\n","\n","  fontdict = {'fontsize': 14}\n","\n","  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n","  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n","\n","  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","  plt.show()"],"metadata":{"id":"aRVdeXwvRnlO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Translate function (which internally calls the evaluate function)\n","def translate(sentence, max_length_inp, max_length_targ, inp_lang, targ_lang):\n","  result, sentence, attention_plot = evaluate(sentence, max_length_inp, max_length_targ, inp_lang, targ_lang)\n","\n","  print('Input: %s' % (sentence))\n","  print('Predicted translation: {}'.format(result))\n","\n","  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n","  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"],"metadata":{"id":"-bY2tITlRwzW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uDYOIqx3Gl7u","executionInfo":{"status":"ok","timestamp":1668375244568,"user_tz":360,"elapsed":850,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"07579b24-9851-45de-aec8-365adcd74a73"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f5b4e0f9390>"]},"metadata":{},"execution_count":101}]},{"cell_type":"code","source":["sentence = 'run'\n","translate(sentence, trainX.shape[1], trainY.shape[1], en_tokenizer, fr_tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":676},"id":"Ri-EDwReE5N2","executionInfo":{"status":"ok","timestamp":1668376624922,"user_tz":360,"elapsed":280,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"623d6697-ed90-425b-a3d5-e058f303dd45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: <start> run <end>\n","Predicted translation: fuyez <end> \n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x720 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["### Bleu score"],"metadata":{"id":"XtzobayqbxP3"}},{"cell_type":"code","source":["from nltk.translate.bleu_score import corpus_bleu\n","\n","def code_to_text(sentence, tokenizer):\n","    result = ''\n","    for j in sentence:\n","        if j != 2 and j != 1:\n","            result += tokenizer.index_word[j] + ' '\n","        if j == 2:\n","            break\n","    return result\n","\n","def evaluate_model(testX, testY, max_length_inp, max_length_targ, inp_lang, targ_lang):\n","    actual, predicted = [], []\n","    bleu = 0\n","    for i, sentence in enumerate(testX):\n","        \n","        # convert encoded source back to text\n","        og_sentence = code_to_text(sentence, inp_lang)\n","        translation = code_to_text(testY[i], targ_lang)\n","        # translate to target lang\n","        result, sentence, attention_plot = evaluate(og_sentence, max_length_inp, max_length_targ, inp_lang, targ_lang)\n","        if i < 20:\n","            print('src=[%s], target=[%s], predicted=[%s]\\n' % (og_sentence, translation, result))\n","        actual.append([sentence.split()])\n","        predicted.append(result.split()[:-1])\n","\n","    print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n","    print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.0, 1, 0, 0)))\n","    print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0, 0, 1, 0)))\n","    print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0, 0, 0, 1)))"],"metadata":{"id":"Psf2JBfPHwko"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluate_model(trainX, trainY, trainX.shape[1], trainY.shape[1], en_tokenizer, fr_tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"drxJ1EkJiiUT","executionInfo":{"status":"error","timestamp":1668381620694,"user_tz":360,"elapsed":1935107,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"6c04bfca-46d4-453c-9b9c-5638db8965a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["src=[you must be mistaken ], target=[tu dois faire erreur ], predicted=[vous devez etre malade <end> ]\n","\n","src=[dont stand in my way ], target=[ne te mets pas dans mon chemin ], predicted=[ne te mets pas dans mon chemin <end> ]\n","\n","src=[i was dismissed ], target=[on ma licencie ], predicted=[jai ete licencie <end> ]\n","\n","src=[youve found it ], target=[tu las trouvee ], predicted=[tu las trouve <end> ]\n","\n","src=[are you there ], target=[tes la ], predicted=[vous etes labas <end> ]\n","\n","src=[do you like summer ], target=[aimezvous lete ], predicted=[aimestu lete <end> ]\n","\n","src=[he has good eyesight ], target=[il a une bonne vue ], predicted=[il a une bonne vue <end> ]\n","\n","src=[tom loves his work ], target=[tom aime son emploi ], predicted=[tom aime son emploi <end> ]\n","\n","src=[i have one question ], target=[jai une question ], predicted=[jai une question <end> ]\n","\n","src=[i know tom is in ], target=[je sais que tom est partant ], predicted=[je sais que tom est partant <end> ]\n","\n","src=[he remained dumb ], target=[il est reste sans voix ], predicted=[il est reste muet <end> ]\n","\n","src=[why are you so happy ], target=[pourquoi etesvous si heureuses ], predicted=[pourquoi estu si heureux <end> ]\n","\n","src=[i am a muslim ], target=[je suis musulmane ], predicted=[je suis musulman <end> ]\n","\n","src=[youre very funny ], target=[tu es tres marrant ], predicted=[vous etes tres marrants <end> ]\n","\n","src=[did i give it to you ], target=[te laije donnee ], predicted=[vous aije bien sortie <end> ]\n","\n","src=[ill ring you back ], target=[je te rappelle ], predicted=[je vous vous vous <end> ]\n","\n","src=[we can talk outside ], target=[nous pouvons parler dehors ], predicted=[nous pouvons parler dehors <end> ]\n","\n","src=[quit bellyaching ], target=[arrete de raler ], predicted=[arrete de raler <end> ]\n","\n","src=[im rather busy ], target=[je suis plutot occupe ], predicted=[je suis plutot occupe <end> ]\n","\n","src=[it became a habit ], target=[cest devenu une habitude ], predicted=[cest devenu une epidemie <end> ]\n","\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-133-9ffeb18ddc49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfr_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-132-31ec9d362b85>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(testX, testY, max_length_inp, max_length_targ, inp_lang, targ_lang)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtranslation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode_to_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg_lang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# translate to target lang\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mog_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length_targ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg_lang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'src=[%s], target=[%s], predicted=[%s]\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mog_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-98-740ba33bfa0e>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(sentence, max_length_inp, max_length_targ, inp_lang, targ_lang)\u001b[0m\n\u001b[1;32m     30\u001b[0m     predictions, dec_hidden, attention_weights = decoder(dec_input,\n\u001b[1;32m     31\u001b[0m                                                          \u001b[0mdec_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                                                          enc_out)\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Store the attention weights to plot later on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m       \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_in_current_and_subclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1013\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1014\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-86-d8018b592929>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, hidden, enc_output)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# context_vector shape == (batch_size, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# attention_weights shape == (batch_size, max_length, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mcontext_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# x shape after passing through embedding == (batch_size, 1, embedding_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1013\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1014\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-84-297d21adef4b>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, query, values)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# the shape of the tensor before applying self.V is (batch_size, max_length, units)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     score = self.V(tf.nn.tanh(\n\u001b[0;32m---> 21\u001b[0;31m         self.W1(query_with_time_axis) + self.W2(values)))\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# attention_weights shape == (batch_size, max_length, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["code_to_text(testY[2], fr_tokenizer)"],"metadata":{"id":"LFWzaWQmxNoB","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1668376318423,"user_tz":360,"elapsed":265,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"019543e3-7b98-42b5-a240-ab4a3090b40e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<start> <end>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":115}]},{"cell_type":"code","source":["testY.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a3SpeNPc-c80","executionInfo":{"status":"ok","timestamp":1668376660867,"user_tz":360,"elapsed":1238,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"2ff4bd1b-1c86-465b-bc8e-319a6f2a0a70"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5000, 57)"]},"metadata":{},"execution_count":120}]},{"cell_type":"code","source":[],"metadata":{"id":"MTjpn_F1__j0"},"execution_count":null,"outputs":[]}]}