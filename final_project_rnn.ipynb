{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOFQ+IlV5JKtfOj8PQZ7O4h"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"_3EznmAC4f62","executionInfo":{"status":"ok","timestamp":1668553961211,"user_tz":360,"elapsed":3436,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from keras.preprocessing.text import Tokenizer\n","from keras_preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical\n","import os\n","import string\n","import re\n","import pickle\n","from pickle import dump\n","import unicodedata\n","from unicodedata import normalize\n","import random"]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pWFhZxx-CFyv","executionInfo":{"status":"ok","timestamp":1668553984645,"user_tz":360,"elapsed":23445,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"64acaef6-8b6c-47e1-a303-11a9d74c5e76"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}]},{"cell_type":"code","source":["cd gdrive/MyDrive"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EMV9gGpbF5lC","executionInfo":{"status":"ok","timestamp":1668553984646,"user_tz":360,"elapsed":13,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"b529ec2c-e2fe-4179-d41f-4261f127a908"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive\n"]}]},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_JMjfgGJ7f7t","executionInfo":{"status":"ok","timestamp":1668553984784,"user_tz":360,"elapsed":144,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"94921dfb-d8b1-41bf-d61c-8047e163e9e8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Nov 15 23:13:05 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["# Dataset preprocessing"],"metadata":{"id":"DqFN2HRcRRED"}},{"cell_type":"markdown","source":["### Europarl dataset"],"metadata":{"id":"KZK4o7ujRsTV"}},{"cell_type":"code","source":["# load doc into memory\n","def load_doc(filename):\n","\tfile = open(filename, mode='rt', encoding='utf-8')\n","\ttext = file.read()\n","\tfile.close()\n","\treturn text\n"," \n","# split a loaded document into sentences\n","def to_sentences(doc):\n","\treturn doc.strip().split('\\n')\n"," \n","# clean a list of lines\n","def clean_lines(lines):\n","\tcleaned = list()\n","\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n","\ttable = str.maketrans('', '', string.punctuation)\n","\tfor line in lines:\n","\n","\t\tline = normalize('NFD', line).encode('ascii', 'ignore')\n","\t\tline = line.decode('UTF-8')\n","\n","\t\tline = line.split()\n","\n","\t\tline = [word.lower() for word in line]\n","\n","\t\tline = [word.translate(table) for word in line]\n","\n","\t\tline = [re_print.sub('', w) for w in line]\n","\n","\t\tline = [word for word in line if word.isalpha()]\n","\t\tline = ' '.join(line)\n","\t\tline = '<start> ' + line + ' <end>'\n","\t\t# store as string\n","\t\tcleaned.append(line)\n","\treturn cleaned\n"," \n","# save a list of clean sentences to file\n","def save_clean_sentences(sentences, filename):\n","\tdump(sentences, open(filename, 'wb'))\n","\tprint('Saved: %s' % filename)\n","\n","def load_datasets(filename):\n","    return pickle.load(open(filename, 'rb'))\n","\n","def produce_train_test(en, fr, ratio = 0.9, total_size = 5000):\n","    n_train = int(total_size * ratio)\n","    indexes = random.sample(range(total_size), n_train)\n","    trainX =  en[indexes]\n","    trainY = fr[indexes]\n","\n","    testX = en[[i for i in range(total_size) if i not in indexes]]\n","    testY = fr[[i for i in range(total_size) if i not in indexes]]\n","    return trainX, trainY, testX, testY\n","\n","# fit a tokenizer\n","def create_tokenizer(lines):\n","\ttokenizer = Tokenizer(filters = '')\n","\ttokenizer.fit_on_texts(lines)\n","\treturn tokenizer\n","\n","\n","# max sentence length\n","def max_length(lines):\n","\treturn max(len(line.split()) for line in lines)\n","\n","# encode and pad sequences\n","def encode_sequences(tokenizer, length, lines):\n","\tX = tokenizer.texts_to_sequences(lines)\n","\tX = pad_sequences(X, maxlen=length, padding='post')\n","\treturn X\n"," "],"metadata":{"id":"K15x31dSGcdw","executionInfo":{"status":"ok","timestamp":1668553995918,"user_tz":360,"elapsed":98,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# load English data\n","filename = 'europarl-v7.fr-en.en'\n","doc = load_doc(filename)\n","en_sentences = to_sentences(doc)\n","en_sentences = clean_lines(en_sentences)\n"," \n","# load French data\n","filename = 'europarl-v7.fr-en.fr'\n","doc = load_doc(filename)\n","fr_sentences = to_sentences(doc)\n","fr_sentences = clean_lines(fr_sentences)"],"metadata":{"id":"N_WSEGKdQ7er"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save cleaned dataset\n","save_clean_sentences(en_sentences, 'english.pkl')\n","save_clean_sentences(fr_sentences, 'french.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aJvVPsgeHLl4","executionInfo":{"status":"ok","timestamp":1666555965963,"user_tz":300,"elapsed":6049,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"6c8cfae1-6446-4e9d-e7e7-904c75a65a95"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved: english.pkl\n","Saved: french.pkl\n"]}]},{"cell_type":"code","source":["# load cleaned data to generate datasets\n","en_sentences = load_datasets('english.pkl')\n","fr_sentences = load_datasets('french.pkl')"],"metadata":{"id":"8d2El6q6fQHH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_size = 5000\n","en = np.array(en_sentences[:total_size])\n","fr = np.array(fr_sentences[:total_size])"],"metadata":{"id":"D17dvTQueky1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainX, trainY, testX, testY = produce_train_test(en, fr)"],"metadata":{"id":"tYOe1c44YIE0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### manythings dataset"],"metadata":{"id":"hDLFo0eXRf4b"}},{"cell_type":"code","source":["def preprocess_sentence(line):\n","\n","    re_print = re.compile('[^%s]' % re.escape(string.printable))\n","\n","    table = str.maketrans('', '', string.punctuation)\n","\n","    line = normalize('NFD', line).encode('ascii', 'ignore')\n","    line = line.decode('UTF-8')\n","\n","    line = line.split()\n","\n","    line = [word.lower() for word in line]\n","\n","    line = [word.translate(table) for word in line]\n","\n","    line = [re_print.sub('', w) for w in line]\n","\n","    line = [word for word in line if word.isalpha()]\n","    line = ' '.join(line)\n","    line = '<start> ' + line + ' <end>'\n","    return line\n","    \n","import io\n","\n","# Create the Dataset\n","def create_dataset(path, num_examples):\n","    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n","\n","    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t', 2)[:-1]]  for l in lines[:num_examples]]\n","    return zip(*word_pairs)\n"],"metadata":{"id":"WF_k3YokqEUH","executionInfo":{"status":"ok","timestamp":1668555165917,"user_tz":360,"elapsed":3,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["!unzip 'fra-eng.zip'"],"metadata":{"id":"ruFbwTjwREJv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668555174872,"user_tz":360,"elapsed":8843,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"30f1d411-471b-4b78-fbe1-984d3fa870c7"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  fra-eng.zip\n","replace _about.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "]}]},{"cell_type":"code","source":["path_to_file = \"fra.txt\""],"metadata":{"id":"dep5PaXuREVj","executionInfo":{"status":"ok","timestamp":1668555176960,"user_tz":360,"elapsed":150,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["en, fr = create_dataset(path_to_file, None)\n","trainX, trainY, testX, testY = produce_train_test(np.array(en[:50000]), np.array(fr[:50000]), total_size = 50000)"],"metadata":{"id":"JJsXCdA6nynA","executionInfo":{"status":"ok","timestamp":1668555239099,"user_tz":360,"elapsed":62035,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}}},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":["### Create tokenizer "],"metadata":{"id":"DqRyGLhIRYZj"}},{"cell_type":"code","source":["en_tokenizer = create_tokenizer(en)\n","en_vocab_size = len(en_tokenizer.word_index) + 1\n","en_length = max_length(en)\n","print('English Vocabulary Size: %d' % en_vocab_size)\n","print('English Max Length: %d' % (en_length))\n","\n","fr_tokenizer = create_tokenizer(fr)\n","fr_vocab_size = len(fr_tokenizer.word_index) + 1\n","fr_length = max_length(fr)\n","print('French Vocabulary Size: %d' % fr_vocab_size)\n","print('French Max Length: %d' % (fr_length))\n"," \n","# prepare training data\n","trainX = encode_sequences(en_tokenizer, en_length, trainX)\n","trainY = encode_sequences(fr_tokenizer, fr_length, trainY)\n","\n","# prepare validation data\n","testX = encode_sequences(en_tokenizer, en_length, testX)\n","testY = encode_sequences(en_tokenizer, fr_length, testY)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OwhjH4Wgfzy1","executionInfo":{"status":"ok","timestamp":1668555266745,"user_tz":360,"elapsed":4219,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"5b35d3ae-81b0-4f44-a587-830e9caa57c7"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["English Vocabulary Size: 15826\n","English Max Length: 49\n","French Vocabulary Size: 30186\n","French Max Length: 57\n"]}]},{"cell_type":"code","source":["trainX.shape, trainY.shape, testX.shape, testY.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wBL6O2cmgtPd","executionInfo":{"status":"ok","timestamp":1668555267286,"user_tz":360,"elapsed":5,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"ff2ae11e-6218-4a0f-a230-3aae40310d42"},"execution_count":73,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((45000, 49), (45000, 57), (5000, 49), (5000, 57))"]},"metadata":{},"execution_count":73}]},{"cell_type":"code","source":["def convert(lang, tensor):\n","  for t in tensor:\n","    if t != 0:\n","      print (\"%d ----> %s\" % (t, lang.index_word[t]))\n","      \n","print (\"Input Language; index to word mapping\")\n","convert(en_tokenizer, trainX[0])\n","print ()\n","print (\"Target Language; index to word mapping\")\n","convert(fr_tokenizer, trainY[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3CL1zkgsavIP","executionInfo":{"status":"ok","timestamp":1668555267424,"user_tz":360,"elapsed":4,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"b4a19f58-0ade-4694-d522-3956f3394ddd"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["Input Language; index to word mapping\n","1 ----> <start>\n","3 ----> i\n","33 ----> like\n","244 ----> being\n","35 ----> with\n","4 ----> you\n","2 ----> <end>\n","\n","Target Language; index to word mapping\n","1 ----> <start>\n","198 ----> jaime\n","57 ----> etre\n","21 ----> en\n","55 ----> votre\n","1429 ----> compagnie\n","2 ----> <end>\n"]}]},{"cell_type":"markdown","source":["# Model Parameters"],"metadata":{"id":"ZM4rjYGnavkU"}},{"cell_type":"code","source":["BUFFER_SIZE = len(trainX)\n","BATCH_SIZE = 64\n","steps_per_epoch = len(trainY)//BATCH_SIZE\n","embedding_dim = 256\n","units = 1024\n","architecture = 'gru' # gru, rnn"],"metadata":{"id":"5iVIC442LJ3o","executionInfo":{"status":"ok","timestamp":1668555267950,"user_tz":360,"elapsed":2,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["dataset = tf.data.Dataset.from_tensor_slices((trainX, trainY)).shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"],"metadata":{"id":"tp5Iw_n0KNLm","executionInfo":{"status":"ok","timestamp":1668555269542,"user_tz":360,"elapsed":151,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}}},"execution_count":76,"outputs":[]},{"cell_type":"code","source":["example_input_batch, example_target_batch = next(iter(dataset))\n","example_input_batch.shape, example_target_batch.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fcPqSjSfLa9S","executionInfo":{"status":"ok","timestamp":1668555270630,"user_tz":360,"elapsed":270,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"6ac5ed3d-d9ec-4b39-8cb3-f060e5cd161f"},"execution_count":77,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([64, 49]), TensorShape([64, 57]))"]},"metadata":{},"execution_count":77}]},{"cell_type":"markdown","source":["# Encoder class"],"metadata":{"id":"GiZRSIoiHfTZ"}},{"cell_type":"code","source":["# Encoder class\n","class Encoder(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n","        super(Encoder, self).__init__()\n","        self.batch_sz = batch_sz\n","        self.enc_units = enc_units\n","\n","        # Embed the vocab to a dense embedding \n","        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","\n","        # GRU Layer\n","        # glorot_uniform: Initializer for the recurrent_kernel weights matrix, \n","        # used for the linear transformation of the recurrent state\n","        if architecture == 'gru':\n","            self.rnn = tf.keras.layers.GRU(self.enc_units,\n","                                            return_sequences=True,\n","                                            return_state=True,\n","                                            recurrent_initializer='glorot_uniform')\n","        if architecture == 'rnn':\n","            self.rnn = tf.keras.layers.SimpleRNN(self.enc_units,\n","                                            return_sequences=True,\n","                                            return_state=True,\n","                                            recurrent_initializer='glorot_uniform')     \n","\n","    # Encoder network comprises an Embedding layer followed by a GRU layer\n","    def call(self, x, hidden):\n","        x = self.embedding(x)\n","        output, state = self.rnn(x, initial_state=hidden)\n","        return output, state\n","\n","    # To initialize the hidden state\n","    def initialize_hidden_state(self):\n","        return tf.zeros((self.batch_sz, self.enc_units))"],"metadata":{"id":"ol5o64Ou_Wf_","executionInfo":{"status":"ok","timestamp":1668555271030,"user_tz":360,"elapsed":2,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}}},"execution_count":78,"outputs":[]},{"cell_type":"code","source":["encoder = Encoder(en_vocab_size, embedding_dim, units, BATCH_SIZE)\n","\n","sample_hidden = encoder.initialize_hidden_state()\n","sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n","\n","print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n","print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZamiUpQ-LgJ_","executionInfo":{"status":"ok","timestamp":1668555271193,"user_tz":360,"elapsed":5,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"1a495471-3b4b-410a-c177-6680bb9231d6"},"execution_count":79,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoder output shape: (batch size, sequence length, units) (64, 49, 1024)\n","Encoder Hidden state shape: (batch size, units) (64, 1024)\n"]}]},{"cell_type":"markdown","source":["# Attention layer"],"metadata":{"id":"aTUJxoQZH3A4"}},{"cell_type":"code","source":["# Attention Mechanism\n","class Attention(tf.keras.layers.Layer):\n","  def __init__(self, units):\n","    super(Attention, self).__init__()\n","    self.W1 = tf.keras.layers.Dense(units)\n","    self.W2 = tf.keras.layers.Dense(units)\n","    self.V = tf.keras.layers.Dense(1)\n","\n","  def call(self, query, values):\n","    # query hidden state shape == (batch_size, hidden size)\n","    # values shape == (batch_size, max_len, hidden size)\n","\n","    # we are doing this to broadcast addition along the time axis to calculate the score\n","    # query_with_time_axis shape == (batch_size, 1, hidden size)\n","    query_with_time_axis = tf.expand_dims(query, 1)\n","\n","    # score shape == (batch_size, max_length, 1)\n","    # we get 1 at the last axis because we are applying score to self.V\n","    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n","    score = self.V(tf.nn.tanh(\n","        self.W1(query_with_time_axis) + self.W2(values)))\n","\n","    # attention_weights shape == (batch_size, max_length, 1)\n","    attention_weights = tf.nn.softmax(score, axis=1)\n","\n","    # context_vector shape after sum == (batch_size, hidden_size)\n","    context_vector = attention_weights * values\n","    context_vector = tf.reduce_sum(context_vector, axis=1)\n","\n","    return context_vector, attention_weights"],"metadata":{"id":"e5wKEbDeH2hB","executionInfo":{"status":"ok","timestamp":1668555271597,"user_tz":360,"elapsed":2,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}}},"execution_count":80,"outputs":[]},{"cell_type":"code","source":["attention_layer = Attention(10)\n","attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n","\n","print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n","print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"],"metadata":{"id":"7_YOjEzZL2LN","executionInfo":{"status":"ok","timestamp":1668555271834,"user_tz":360,"elapsed":120,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ff1386da-0f92-4562-fac5-bc23eef2fb90"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["Attention result shape: (batch size, units) (64, 1024)\n","Attention weights shape: (batch_size, sequence_length, 1) (64, 49, 1)\n"]}]},{"cell_type":"markdown","source":["# Decoder Class"],"metadata":{"id":"mfTebVydH8eO"}},{"cell_type":"code","source":["# Decoder class\n","class Decoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n","    super(Decoder, self).__init__()\n","    self.batch_sz = batch_sz\n","    self.dec_units = dec_units\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.SimpleRNN(self.dec_units,\n","                                   return_sequences=True,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","    self.fc = tf.keras.layers.Dense(vocab_size)\n","\n","    # Used for attention\n","    self.attention = Attention(self.dec_units)\n","\n","  def call(self, x, hidden, enc_output):\n","    # x shape == (batch_size, 1)\n","    # hidden shape == (batch_size, max_length)\n","    # enc_output shape == (batch_size, max_length, hidden_size)\n","\n","    # context_vector shape == (batch_size, hidden_size)\n","    # attention_weights shape == (batch_size, max_length, 1)\n","    context_vector, attention_weights = self.attention(hidden, enc_output)\n","\n","    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n","    x = self.embedding(x)\n","\n","    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n","    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n","\n","    # passing the concatenated vector to the GRU\n","    output, state = self.gru(x)\n","\n","    # output shape == (batch_size * 1, hidden_size)\n","    output = tf.reshape(output, (-1, output.shape[2]))\n","\n","    # output shape == (batch_size, vocab)\n","    x = self.fc(output)\n","\n","    return x, state, attention_weights"],"metadata":{"id":"0Y3BMguw_-JD","executionInfo":{"status":"ok","timestamp":1668555272406,"user_tz":360,"elapsed":3,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}}},"execution_count":82,"outputs":[]},{"cell_type":"code","source":["decoder = Decoder(fr_vocab_size, embedding_dim, units, BATCH_SIZE)\n","\n","sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n","                                      sample_hidden, sample_output)\n","\n","print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"],"metadata":{"id":"IqzCT8xVL_3k","executionInfo":{"status":"ok","timestamp":1668555272602,"user_tz":360,"elapsed":9,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b2d4fd1b-92fd-431b-fcd7-8b46402b8048"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["Decoder output shape: (batch_size, vocab size) (64, 30186)\n"]}]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"gwyUNfIQP20t"}},{"cell_type":"code","source":["# Initialize optimizer and loss functions\n","optimizer = tf.keras.optimizers.Adam()\n","\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')\n","\n","# Loss function\n","def loss_function(real, pred):\n","\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  loss_ = loss_object(real, pred)\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype)\n","  loss_ *= mask\n","\n","  return tf.reduce_mean(loss_)"],"metadata":{"id":"mkibV-bzMAMS","executionInfo":{"status":"ok","timestamp":1668555274831,"user_tz":360,"elapsed":161,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}}},"execution_count":84,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","checkpoint_dir = './rnn_training_checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n","                                 encoder=encoder,\n","                                 decoder=decoder)"],"metadata":{"id":"mL-Y6lXWP4yD","executionInfo":{"status":"ok","timestamp":1668555275319,"user_tz":360,"elapsed":2,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}}},"execution_count":85,"outputs":[]},{"cell_type":"code","source":["@tf.function\n","def train_step(inp, targ, enc_hidden):\n","  loss = 0\n","\n","  # tf.GradientTape() -- record operations for automatic differentiation\n","  with tf.GradientTape() as tape:\n","    enc_output, enc_hidden = encoder(inp, enc_hidden)\n","\n","    # dec_hidden is used by attention, hence is the same enc_hidden\n","    dec_hidden = enc_hidden\n","\n","    # <start> token is the initial decoder input\n","    dec_input = tf.expand_dims([fr_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n","\n","    # Teacher forcing - feeding the target as the next input\n","    for t in range(1, targ.shape[1]):\n","\n","      # Pass enc_output to the decoder\n","      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n","\n","      # Compute the loss\n","      loss += loss_function(targ[:, t], predictions)\n","\n","      # Use teacher forcing\n","      dec_input = tf.expand_dims(targ[:, t], 1)\n","\n","  # As this function is called per batch, compute the batch_loss\n","  batch_loss = (loss / int(targ.shape[1]))\n","\n","  # Get the model's variables\n","  variables = encoder.trainable_variables + decoder.trainable_variables\n","\n","  # Compute the gradients\n","  gradients = tape.gradient(loss, variables)\n","\n","  # Update the variables of the model/network\n","  optimizer.apply_gradients(zip(gradients, variables))\n","\n","  return batch_loss"],"metadata":{"id":"MNiTqwl6P7mt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","EPOCHS = 30\n","history = []\n","# Training loop\n","for epoch in range(EPOCHS):\n","  start = time.time()\n","\n","  # Initialize the hidden state\n","  enc_hidden = encoder.initialize_hidden_state()\n","  total_loss = 0\n","\n","  # Loop through the dataset\n","  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n","\n","    # Call the train method\n","    batch_loss = train_step(inp, targ, enc_hidden)\n","\n","    # Compute the loss (per batch)\n","    total_loss += batch_loss\n","\n","    if batch % 100 == 0:\n","      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n","                                                   batch,\n","                                                   batch_loss.numpy()))\n","  # Save (checkpoint) the model every 2 epochs\n","  if (epoch + 1) % 2 == 0:\n","    checkpoint.save(file_prefix = checkpoint_prefix)\n","\n","  # Output the loss observed until that epoch\n","  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n","                                      total_loss / steps_per_epoch))\n","  \n","  history.append(total_loss / steps_per_epoch)\n","  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"],"metadata":{"id":"RM3qVshkQAbR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668463836584,"user_tz":360,"elapsed":14598124,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"4e862413-1cf3-41f0-d2a8-fa54c1cba6d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 Batch 0 Loss 0.9247\n","Epoch 1 Batch 100 Loss 0.5738\n","Epoch 1 Batch 200 Loss 0.5589\n","Epoch 1 Batch 300 Loss 0.5465\n","Epoch 1 Batch 400 Loss 0.5652\n","Epoch 1 Batch 500 Loss 0.5834\n","Epoch 1 Batch 600 Loss 0.5513\n","Epoch 1 Batch 700 Loss 0.5525\n","Epoch 1 Loss 0.5681\n","Time taken for 1 epoch 509.09537863731384 sec\n","\n","Epoch 2 Batch 0 Loss 0.5590\n","Epoch 2 Batch 100 Loss 0.5653\n","Epoch 2 Batch 200 Loss 0.5756\n","Epoch 2 Batch 300 Loss 0.5537\n","Epoch 2 Batch 400 Loss 0.5689\n","Epoch 2 Batch 500 Loss 0.5505\n","Epoch 2 Batch 600 Loss 0.5672\n","Epoch 2 Batch 700 Loss 0.5606\n","Epoch 2 Loss 0.5616\n","Time taken for 1 epoch 475.45911502838135 sec\n","\n","Epoch 3 Batch 0 Loss 0.5514\n","Epoch 3 Batch 100 Loss 0.5681\n","Epoch 3 Batch 200 Loss 0.6006\n","Epoch 3 Batch 300 Loss 0.5734\n","Epoch 3 Batch 400 Loss 0.5553\n","Epoch 3 Batch 500 Loss 0.5551\n","Epoch 3 Batch 600 Loss 0.5522\n","Epoch 3 Batch 700 Loss 0.5943\n","Epoch 3 Loss 0.5631\n","Time taken for 1 epoch 473.88068771362305 sec\n","\n","Epoch 4 Batch 0 Loss 0.5538\n","Epoch 4 Batch 100 Loss 0.5667\n","Epoch 4 Batch 200 Loss 0.5684\n","Epoch 4 Batch 300 Loss 0.5461\n","Epoch 4 Batch 400 Loss 0.5919\n","Epoch 4 Batch 500 Loss 0.5783\n","Epoch 4 Batch 600 Loss 0.5528\n","Epoch 4 Batch 700 Loss 0.5577\n","Epoch 4 Loss 0.5657\n","Time taken for 1 epoch 476.17243361473083 sec\n","\n","Epoch 5 Batch 0 Loss 0.5795\n","Epoch 5 Batch 100 Loss 0.5588\n","Epoch 5 Batch 200 Loss 0.4891\n","Epoch 5 Batch 300 Loss 0.4345\n","Epoch 5 Batch 400 Loss 0.4191\n","Epoch 5 Batch 500 Loss 0.3945\n","Epoch 5 Batch 600 Loss 0.3700\n","Epoch 5 Batch 700 Loss 0.3437\n","Epoch 5 Loss 0.4403\n","Time taken for 1 epoch 481.6816108226776 sec\n","\n","Epoch 6 Batch 0 Loss 0.3234\n","Epoch 6 Batch 100 Loss 0.3316\n","Epoch 6 Batch 200 Loss 0.2808\n","Epoch 6 Batch 300 Loss 0.3060\n","Epoch 6 Batch 400 Loss 0.3058\n","Epoch 6 Batch 500 Loss 0.2686\n","Epoch 6 Batch 600 Loss 0.2659\n","Epoch 6 Batch 700 Loss 0.2079\n","Epoch 6 Loss 0.2797\n","Time taken for 1 epoch 487.1584782600403 sec\n","\n","Epoch 7 Batch 0 Loss 0.1957\n","Epoch 7 Batch 100 Loss 0.1912\n","Epoch 7 Batch 200 Loss 0.1806\n","Epoch 7 Batch 300 Loss 0.2115\n","Epoch 7 Batch 400 Loss 0.2062\n","Epoch 7 Batch 500 Loss 0.1928\n","Epoch 7 Batch 600 Loss 0.1968\n","Epoch 7 Batch 700 Loss 0.1694\n","Epoch 7 Loss 0.1940\n","Time taken for 1 epoch 486.2265610694885 sec\n","\n","Epoch 8 Batch 0 Loss 0.1414\n","Epoch 8 Batch 100 Loss 0.1275\n","Epoch 8 Batch 200 Loss 0.1387\n","Epoch 8 Batch 300 Loss 0.1357\n","Epoch 8 Batch 400 Loss 0.1381\n","Epoch 8 Batch 500 Loss 0.1471\n","Epoch 8 Batch 600 Loss 0.1595\n","Epoch 8 Batch 700 Loss 0.1613\n","Epoch 8 Loss 0.1410\n","Time taken for 1 epoch 488.81580233573914 sec\n","\n","Epoch 9 Batch 0 Loss 0.1117\n","Epoch 9 Batch 100 Loss 0.1101\n","Epoch 9 Batch 200 Loss 0.1113\n","Epoch 9 Batch 300 Loss 0.1095\n","Epoch 9 Batch 400 Loss 0.1224\n","Epoch 9 Batch 500 Loss 0.1133\n","Epoch 9 Batch 600 Loss 0.1461\n","Epoch 9 Batch 700 Loss 0.1262\n","Epoch 9 Loss 0.1095\n","Time taken for 1 epoch 486.40390181541443 sec\n","\n","Epoch 10 Batch 0 Loss 0.0833\n","Epoch 10 Batch 100 Loss 0.0906\n","Epoch 10 Batch 200 Loss 0.0856\n","Epoch 10 Batch 300 Loss 0.0867\n","Epoch 10 Batch 400 Loss 0.0900\n","Epoch 10 Batch 500 Loss 0.1022\n","Epoch 10 Batch 600 Loss 0.1090\n","Epoch 10 Batch 700 Loss 0.0811\n","Epoch 10 Loss 0.0907\n","Time taken for 1 epoch 487.622150182724 sec\n","\n","Epoch 11 Batch 0 Loss 0.0600\n","Epoch 11 Batch 100 Loss 0.0577\n","Epoch 11 Batch 200 Loss 0.0592\n","Epoch 11 Batch 300 Loss 0.0743\n","Epoch 11 Batch 400 Loss 0.0658\n","Epoch 11 Batch 500 Loss 0.0687\n","Epoch 11 Batch 600 Loss 0.0855\n","Epoch 11 Batch 700 Loss 0.0789\n","Epoch 11 Loss 0.0797\n","Time taken for 1 epoch 486.3495571613312 sec\n","\n","Epoch 12 Batch 0 Loss 0.0562\n","Epoch 12 Batch 100 Loss 0.0621\n","Epoch 12 Batch 200 Loss 0.0866\n","Epoch 12 Batch 300 Loss 0.0723\n","Epoch 12 Batch 400 Loss 0.0717\n","Epoch 12 Batch 500 Loss 0.0801\n","Epoch 12 Batch 600 Loss 0.0707\n","Epoch 12 Batch 700 Loss 0.0692\n","Epoch 12 Loss 0.0719\n","Time taken for 1 epoch 487.70015263557434 sec\n","\n","Epoch 13 Batch 0 Loss 0.0618\n","Epoch 13 Batch 100 Loss 0.0521\n","Epoch 13 Batch 200 Loss 0.0734\n","Epoch 13 Batch 300 Loss 0.0630\n","Epoch 13 Batch 400 Loss 0.0628\n","Epoch 13 Batch 500 Loss 0.0604\n","Epoch 13 Batch 600 Loss 0.0848\n","Epoch 13 Batch 700 Loss 0.0757\n","Epoch 13 Loss 0.0666\n","Time taken for 1 epoch 486.3161437511444 sec\n","\n","Epoch 14 Batch 0 Loss 0.0657\n","Epoch 14 Batch 100 Loss 0.0448\n","Epoch 14 Batch 200 Loss 0.0604\n","Epoch 14 Batch 300 Loss 0.0500\n","Epoch 14 Batch 400 Loss 0.0541\n","Epoch 14 Batch 500 Loss 0.0722\n","Epoch 14 Batch 600 Loss 0.0746\n","Epoch 14 Batch 700 Loss 0.0707\n","Epoch 14 Loss 0.0639\n","Time taken for 1 epoch 489.04378628730774 sec\n","\n","Epoch 15 Batch 0 Loss 0.0452\n","Epoch 15 Batch 100 Loss 0.0623\n","Epoch 15 Batch 200 Loss 0.0646\n","Epoch 15 Batch 300 Loss 0.0525\n","Epoch 15 Batch 400 Loss 0.0706\n","Epoch 15 Batch 500 Loss 0.0694\n","Epoch 15 Batch 600 Loss 0.0734\n","Epoch 15 Batch 700 Loss 0.0687\n","Epoch 15 Loss 0.0616\n","Time taken for 1 epoch 486.55169916152954 sec\n","\n","Epoch 16 Batch 0 Loss 0.0330\n","Epoch 16 Batch 100 Loss 0.0690\n","Epoch 16 Batch 200 Loss 0.0657\n","Epoch 16 Batch 300 Loss 0.0564\n","Epoch 16 Batch 400 Loss 0.0651\n","Epoch 16 Batch 500 Loss 0.0562\n","Epoch 16 Batch 600 Loss 0.0616\n","Epoch 16 Batch 700 Loss 0.0703\n","Epoch 16 Loss 0.0592\n","Time taken for 1 epoch 487.7827503681183 sec\n","\n","Epoch 17 Batch 0 Loss 0.0348\n","Epoch 17 Batch 100 Loss 0.0451\n","Epoch 17 Batch 200 Loss 0.0447\n","Epoch 17 Batch 300 Loss 0.0561\n","Epoch 17 Batch 400 Loss 0.0503\n","Epoch 17 Batch 500 Loss 0.0627\n","Epoch 17 Batch 600 Loss 0.0687\n","Epoch 17 Batch 700 Loss 0.0643\n","Epoch 17 Loss 0.0578\n","Time taken for 1 epoch 486.2787001132965 sec\n","\n","Epoch 18 Batch 0 Loss 0.0478\n","Epoch 18 Batch 100 Loss 0.0582\n","Epoch 18 Batch 200 Loss 0.0389\n","Epoch 18 Batch 300 Loss 0.0477\n","Epoch 18 Batch 400 Loss 0.0625\n","Epoch 18 Batch 500 Loss 0.0583\n","Epoch 18 Batch 600 Loss 0.0648\n","Epoch 18 Batch 700 Loss 0.0599\n","Epoch 18 Loss 0.0562\n","Time taken for 1 epoch 489.22883796691895 sec\n","\n","Epoch 19 Batch 0 Loss 0.0425\n","Epoch 19 Batch 100 Loss 0.0388\n","Epoch 19 Batch 200 Loss 0.0464\n","Epoch 19 Batch 300 Loss 0.0597\n","Epoch 19 Batch 400 Loss 0.0680\n","Epoch 19 Batch 500 Loss 0.0559\n","Epoch 19 Batch 600 Loss 0.0784\n","Epoch 19 Batch 700 Loss 0.0495\n","Epoch 19 Loss 0.0554\n","Time taken for 1 epoch 486.4860439300537 sec\n","\n","Epoch 20 Batch 0 Loss 0.0468\n","Epoch 20 Batch 100 Loss 0.0342\n","Epoch 20 Batch 200 Loss 0.0363\n","Epoch 20 Batch 300 Loss 0.0610\n","Epoch 20 Batch 400 Loss 0.0655\n","Epoch 20 Batch 500 Loss 0.0779\n","Epoch 20 Batch 600 Loss 0.0762\n","Epoch 20 Batch 700 Loss 0.0533\n","Epoch 20 Loss 0.0541\n","Time taken for 1 epoch 487.944162607193 sec\n","\n","Epoch 21 Batch 0 Loss 0.0483\n","Epoch 21 Batch 100 Loss 0.0427\n","Epoch 21 Batch 200 Loss 0.0451\n","Epoch 21 Batch 300 Loss 0.0459\n","Epoch 21 Batch 400 Loss 0.0463\n","Epoch 21 Batch 500 Loss 0.0722\n","Epoch 21 Batch 600 Loss 0.0657\n","Epoch 21 Batch 700 Loss 0.0753\n","Epoch 21 Loss 0.0534\n","Time taken for 1 epoch 486.75089716911316 sec\n","\n","Epoch 22 Batch 0 Loss 0.0431\n","Epoch 22 Batch 100 Loss 0.0536\n","Epoch 22 Batch 200 Loss 0.0439\n","Epoch 22 Batch 300 Loss 0.0491\n","Epoch 22 Batch 400 Loss 0.0597\n","Epoch 22 Batch 500 Loss 0.0421\n","Epoch 22 Batch 600 Loss 0.0561\n","Epoch 22 Batch 700 Loss 0.0578\n","Epoch 22 Loss 0.0526\n","Time taken for 1 epoch 487.82773208618164 sec\n","\n","Epoch 23 Batch 0 Loss 0.0541\n","Epoch 23 Batch 100 Loss 0.0394\n","Epoch 23 Batch 200 Loss 0.0523\n","Epoch 23 Batch 300 Loss 0.0447\n","Epoch 23 Batch 400 Loss 0.0385\n","Epoch 23 Batch 500 Loss 0.0561\n","Epoch 23 Batch 600 Loss 0.0481\n","Epoch 23 Batch 700 Loss 0.0619\n","Epoch 23 Loss 0.0519\n","Time taken for 1 epoch 486.54164242744446 sec\n","\n","Epoch 24 Batch 0 Loss 0.0626\n","Epoch 24 Batch 100 Loss 0.0368\n","Epoch 24 Batch 200 Loss 0.0503\n","Epoch 24 Batch 300 Loss 0.0416\n","Epoch 24 Batch 400 Loss 0.0573\n","Epoch 24 Batch 500 Loss 0.0494\n","Epoch 24 Batch 600 Loss 0.0602\n","Epoch 24 Batch 700 Loss 0.0512\n","Epoch 24 Loss 0.0514\n","Time taken for 1 epoch 487.71023654937744 sec\n","\n","Epoch 25 Batch 0 Loss 0.0702\n","Epoch 25 Batch 100 Loss 0.0443\n","Epoch 25 Batch 200 Loss 0.0544\n","Epoch 25 Batch 300 Loss 0.0602\n","Epoch 25 Batch 400 Loss 0.0700\n","Epoch 25 Batch 500 Loss 0.0558\n","Epoch 25 Batch 600 Loss 0.0522\n","Epoch 25 Batch 700 Loss 0.0632\n","Epoch 25 Loss 0.0506\n","Time taken for 1 epoch 486.45069217681885 sec\n","\n","Epoch 26 Batch 0 Loss 0.0391\n","Epoch 26 Batch 100 Loss 0.0309\n","Epoch 26 Batch 200 Loss 0.0329\n","Epoch 26 Batch 300 Loss 0.0505\n","Epoch 26 Batch 400 Loss 0.0516\n","Epoch 26 Batch 500 Loss 0.0464\n","Epoch 26 Batch 600 Loss 0.0450\n","Epoch 26 Batch 700 Loss 0.0648\n","Epoch 26 Loss 0.0499\n","Time taken for 1 epoch 487.57656836509705 sec\n","\n","Epoch 27 Batch 0 Loss 0.0279\n","Epoch 27 Batch 100 Loss 0.0474\n","Epoch 27 Batch 200 Loss 0.0340\n","Epoch 27 Batch 300 Loss 0.0510\n","Epoch 27 Batch 400 Loss 0.0604\n","Epoch 27 Batch 500 Loss 0.0589\n","Epoch 27 Batch 600 Loss 0.0503\n","Epoch 27 Batch 700 Loss 0.0671\n","Epoch 27 Loss 0.0496\n","Time taken for 1 epoch 486.27288699150085 sec\n","\n","Epoch 28 Batch 0 Loss 0.0397\n","Epoch 28 Batch 100 Loss 0.0563\n","Epoch 28 Batch 200 Loss 0.0553\n","Epoch 28 Batch 300 Loss 0.0579\n","Epoch 28 Batch 400 Loss 0.0459\n","Epoch 28 Batch 500 Loss 0.0489\n","Epoch 28 Batch 600 Loss 0.0526\n","Epoch 28 Batch 700 Loss 0.0549\n","Epoch 28 Loss 0.0493\n","Time taken for 1 epoch 489.6449558734894 sec\n","\n","Epoch 29 Batch 0 Loss 0.0347\n","Epoch 29 Batch 100 Loss 0.0434\n","Epoch 29 Batch 200 Loss 0.0260\n","Epoch 29 Batch 300 Loss 0.0380\n","Epoch 29 Batch 400 Loss 0.0628\n","Epoch 29 Batch 500 Loss 0.0608\n","Epoch 29 Batch 600 Loss 0.0548\n","Epoch 29 Batch 700 Loss 0.0550\n","Epoch 29 Loss 0.0487\n","Time taken for 1 epoch 486.1100368499756 sec\n","\n","Epoch 30 Batch 0 Loss 0.0426\n","Epoch 30 Batch 100 Loss 0.0239\n","Epoch 30 Batch 200 Loss 0.0316\n","Epoch 30 Batch 300 Loss 0.0380\n","Epoch 30 Batch 400 Loss 0.0475\n","Epoch 30 Batch 500 Loss 0.0604\n","Epoch 30 Batch 600 Loss 0.0702\n","Epoch 30 Batch 700 Loss 0.0553\n","Epoch 30 Loss 0.0483\n","Time taken for 1 epoch 487.645179271698 sec\n","\n"]}]},{"cell_type":"markdown","source":["# Evaluation"],"metadata":{"id":"AsyjZbrIbyXh"}},{"cell_type":"code","source":["def plot_training(history):\n","    loss = history\n","    epochs = range(1, len(history) + 1)\n","    \n","    # Plot training and validation loss\n","    plt.plot(epochs, loss, 'bo', label = 'training loss')\n","    plt.title('training loss')\n","    plt.legend()\n"],"metadata":{"id":"afXEh0I3_Ygq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_training(history)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"id":"_y7QDlvX_Zi7","executionInfo":{"status":"ok","timestamp":1668463883580,"user_tz":360,"elapsed":527,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"17884a09-8bc8-4509-e4e6-a485f6f143c8"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["import numpy as np\n","\n","# Evaluate function -- similar to the training loop\n","def evaluate(sentence, max_length_inp, max_length_targ, inp_lang, targ_lang):\n","\n","  # Attention plot (to be plotted later on) -- initialized with max_lengths of both target and input\n","  attention_plot = np.zeros((max_length_targ, max_length_inp))\n","\n","  # Preprocess the sentence given\n","  sentence = preprocess_sentence(sentence)\n","\n","  # Fetch the indices concerning the words in the sentence and pad the sequence\n","  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n","  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n","                                                         maxlen=max_length_inp,\n","                                                         padding='post')\n","  # Convert the inputs to tensors\n","  inputs = tf.convert_to_tensor(inputs)\n","\n","  result = ''\n","\n","  hidden = tf.zeros((1, units))\n","  enc_out, enc_hidden = encoder(inputs, hidden)\n","\n","  dec_hidden = enc_hidden\n","  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n","\n","  # Loop until the max_length is reached for the target lang (ENGLISH)\n","  for t in range(max_length_targ):\n","    predictions, dec_hidden, attention_weights = decoder(dec_input,\n","                                                         dec_hidden,\n","                                                         enc_out)\n","\n","    # Store the attention weights to plot later on\n","    attention_weights = tf.reshape(attention_weights, (-1, ))\n","    attention_plot[t] = attention_weights.numpy()\n","\n","    # Get the prediction with the maximum attention\n","    predicted_id = tf.argmax(predictions[0]).numpy()\n","\n","    # Append the token to the result\n","    result += targ_lang.index_word[predicted_id] + ' '\n","\n","    # If <end> token is reached, return the result, input, and attention plot\n","    if targ_lang.index_word[predicted_id] == '<end>':\n","      return result, sentence, attention_plot\n","\n","    # The predicted ID is fed back into the model\n","    dec_input = tf.expand_dims([predicted_id], 0)\n","\n","  return result, sentence, attention_plot"],"metadata":{"id":"87W9T43zaHYE","executionInfo":{"status":"ok","timestamp":1668555280565,"user_tz":360,"elapsed":1,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}}},"execution_count":86,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","\n","# Function for plotting the attention weights\n","def plot_attention(attention, sentence, predicted_sentence):\n","  fig = plt.figure(figsize=(10,10))\n","  ax = fig.add_subplot(1, 1, 1)\n","  ax.matshow(attention, cmap='viridis')\n","\n","  fontdict = {'fontsize': 14}\n","\n","  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n","  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n","\n","  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","  plt.show()"],"metadata":{"id":"aRVdeXwvRnlO","executionInfo":{"status":"ok","timestamp":1668555280736,"user_tz":360,"elapsed":1,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}}},"execution_count":87,"outputs":[]},{"cell_type":"code","source":["# Translate function (which internally calls the evaluate function)\n","def translate(sentence, max_length_inp, max_length_targ, inp_lang, targ_lang):\n","  result, sentence, attention_plot = evaluate(sentence, max_length_inp, max_length_targ, inp_lang, targ_lang)\n","\n","  print('Input: %s' % (sentence))\n","  print('Predicted translation: {}'.format(result))\n","\n","  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n","  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"],"metadata":{"id":"-bY2tITlRwzW","executionInfo":{"status":"ok","timestamp":1668555280979,"user_tz":360,"elapsed":2,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}}},"execution_count":88,"outputs":[]},{"cell_type":"code","source":["checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uDYOIqx3Gl7u","executionInfo":{"status":"ok","timestamp":1668555283317,"user_tz":360,"elapsed":931,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"31798135-b478-4920-d1db-e3b25cab6c40"},"execution_count":89,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fc56e4d6ad0>"]},"metadata":{},"execution_count":89}]},{"cell_type":"code","source":["sentence = 'dont stand in my way'\n","translate(sentence, trainX.shape[1], trainY.shape[1], en_tokenizer, fr_tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":676},"id":"Ri-EDwReE5N2","executionInfo":{"status":"ok","timestamp":1668556722572,"user_tz":360,"elapsed":424,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"f41fdc15-edbe-49bb-fbf6-29c9eb6c4505"},"execution_count":94,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: <start> dont stand in my way <end>\n","Predicted translation: ne te mets pas dans mon chemin <end> \n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 720x720 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["### Bleu score"],"metadata":{"id":"XtzobayqbxP3"}},{"cell_type":"code","source":["from nltk.translate.bleu_score import corpus_bleu\n","\n","def code_to_text(sentence, tokenizer):\n","    result = ''\n","    for j in sentence:\n","        if j != 2 and j != 1:\n","            result += tokenizer.index_word[j] + ' '\n","        if j == 2:\n","            break\n","    return result\n","\n","def evaluate_model(testX, testY, max_length_inp, max_length_targ, inp_lang, targ_lang):\n","    actual, predicted = [], []\n","    bleu = 0\n","    for i, sentence in enumerate(testX):\n","        \n","        # convert encoded source back to text\n","        og_sentence = code_to_text(sentence, inp_lang)\n","        translation = code_to_text(testY[i], targ_lang)\n","        # translate to target lang\n","        result, sentence, attention_plot = evaluate(og_sentence, max_length_inp, max_length_targ, inp_lang, targ_lang)\n","        if i < 20:\n","            print('src=[%s], target=[%s], predicted=[%s]\\n' % (og_sentence, translation, result))\n","        actual.append([translation.split()])\n","        predicted.append(result.split()[:-1])\n","\n","    print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n","    print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.0, 1, 0, 0)))\n","    print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0, 0, 1, 0)))\n","    print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0, 0, 0, 1)))"],"metadata":{"id":"Psf2JBfPHwko","executionInfo":{"status":"ok","timestamp":1668555296647,"user_tz":360,"elapsed":221,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}}},"execution_count":91,"outputs":[]},{"cell_type":"code","source":["evaluate_model(trainX[:5000], trainY[:5000], testX.shape[1], testY.shape[1], en_tokenizer, fr_tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"drxJ1EkJiiUT","executionInfo":{"status":"ok","timestamp":1668557115814,"user_tz":360,"elapsed":343608,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"c03e0f95-1ce7-40bc-f7b7-6d1706ffe43f"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["src=[i like being with you ], target=[jaime etre en votre compagnie ], predicted=[jaime etre en ta compagnie <end> ]\n","\n","src=[thanks again ], target=[encore une fois merci ], predicted=[encore une fois merci <end> ]\n","\n","src=[is something wrong ], target=[quelque chose ne va pas ], predicted=[quelque chose ne va pas <end> ]\n","\n","src=[get us out of here ], target=[sorteznous dici ], predicted=[sorteznous dici <end> ]\n","\n","src=[get to the point ], target=[viensen au fait ], predicted=[viensen au fait <end> ]\n","\n","src=[tom botched the job ], target=[tom a bacle le travail ], predicted=[tom a bacle le travail <end> ]\n","\n","src=[we realize that ], target=[nous en sommes conscients ], predicted=[nous en sommes conscients <end> ]\n","\n","src=[thats a big deal ], target=[cest une grosse affaire ], predicted=[cest une grosse affaire <end> ]\n","\n","src=[come downtown with us ], target=[venez en ville avec nous ], predicted=[venez en ville avec nous <end> ]\n","\n","src=[are you a christian ], target=[etesvous chretien ], predicted=[etesvous chretien <end> ]\n","\n","src=[we have injuries ], target=[nous avons des blessures ], predicted=[nous avons des blessures <end> ]\n","\n","src=[i just opened it ], target=[je viens de louvrir ], predicted=[je viens de louvrir <end> ]\n","\n","src=[i bought this for you ], target=[jai achete ca pour toi ], predicted=[jai achete ca pour toi <end> ]\n","\n","src=[i ate a slice of ham ], target=[jai mange une tranche de jambon ], predicted=[jai mange une tranche de jambon <end> ]\n","\n","src=[bring wine ], target=[apportez du vin ], predicted=[apportez du vin <end> ]\n","\n","src=[i have cancer ], target=[je suis atteint dun cancer ], predicted=[jai un cancer <end> ]\n","\n","src=[i trust you all ], target=[jai confiance en vous tous ], predicted=[jai vraiment me manquerez <end> ]\n","\n","src=[i want to resign ], target=[je veux demissionner ], predicted=[je veux demissionner <end> ]\n","\n","src=[im optimistic ], target=[je suis optimiste ], predicted=[je suis optimiste <end> ]\n","\n","src=[tom couldve changed ], target=[tom aurait pu changer ], predicted=[tom aurait pu changer <end> ]\n","\n","BLEU-1: 0.784781\n","BLEU-2: 0.681015\n","BLEU-3: 0.581955\n","BLEU-4: 0.425670\n"]}]},{"cell_type":"code","source":["code_to_text(testY[2], fr_tokenizer)"],"metadata":{"id":"LFWzaWQmxNoB","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1668376318423,"user_tz":360,"elapsed":265,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"019543e3-7b98-42b5-a240-ab4a3090b40e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<start> <end>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":115}]},{"cell_type":"code","source":["testY.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a3SpeNPc-c80","executionInfo":{"status":"ok","timestamp":1668376660867,"user_tz":360,"elapsed":1238,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"2ff4bd1b-1c86-465b-bc8e-319a6f2a0a70"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5000, 57)"]},"metadata":{},"execution_count":120}]},{"cell_type":"code","source":["testY[1]"],"metadata":{"id":"MTjpn_F1__j0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668470011235,"user_tz":360,"elapsed":321,"user":{"displayName":"Khiem Nguyen","userId":"18416220429915931108"}},"outputId":"5cfb0499-c6e3-4925-b185-c595ae1f87ae"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":[],"metadata":{"id":"VNyaYZ2oj3it"},"execution_count":null,"outputs":[]}]}